{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['number', 'negative', 'grid']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>...</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Attrition     BusinessTravel              Department  \\\n",
       "0   41          1      Travel_Rarely                   Sales   \n",
       "1   49          0  Travel_Frequently  Research & Development   \n",
       "2   37          1      Travel_Rarely  Research & Development   \n",
       "3   33          0  Travel_Frequently  Research & Development   \n",
       "4   27          0      Travel_Rarely  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EnvironmentSatisfaction  \\\n",
       "0                 1          2  Life Sciences                        2   \n",
       "1                 8          1  Life Sciences                        3   \n",
       "2                 2          2          Other                        4   \n",
       "3                 3          4  Life Sciences                        4   \n",
       "4                 2          1        Medical                        1   \n",
       "\n",
       "   Gender  HourlyRate          ...           NumCompaniesWorked OverTime  \\\n",
       "0  Female          94          ...                            8      Yes   \n",
       "1    Male          61          ...                            1       No   \n",
       "2    Male          92          ...                            6      Yes   \n",
       "3  Female          56          ...                            1      Yes   \n",
       "4    Male          40          ...                            9       No   \n",
       "\n",
       "   PercentSalaryHike RelationshipSatisfaction  TotalWorkingYears  \\\n",
       "0                 11                        1                  8   \n",
       "1                 23                        4                 10   \n",
       "2                 15                        2                  7   \n",
       "3                 11                        3                  8   \n",
       "4                 12                        4                  6   \n",
       "\n",
       "   WorkLifeBalance YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                1              6                   4   \n",
       "1                3             10                   7   \n",
       "2                3              0                   0   \n",
       "3                3              8                   7   \n",
       "4                3              2                   2   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                     5  \n",
       "1                        1                     7  \n",
       "2                        0                     0  \n",
       "3                        3                     0  \n",
       "4                        2                     2  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "\n",
    "# Importing and reading CSV file\n",
    "file_input = 'C:\\\\Users\\\\Sneha Rani\\\\CapstoneProject-LR\\\\ibm-hr-attrition.csv'\n",
    "df1 = pd.read_csv(file_input, index_col=None)\n",
    "\n",
    "# Pre cleaned the dataset by selecting significant columns\n",
    "df2 = df1[['Age','Attrition','BusinessTravel','Department','DistanceFromHome','Education','EducationField',\n",
    "           'EnvironmentSatisfaction','Gender','HourlyRate','JobInvolvement','JobRole','JobSatisfaction','MaritalStatus','MonthlyIncome',\n",
    "           'NumCompaniesWorked','OverTime','PercentSalaryHike','RelationshipSatisfaction','TotalWorkingYears',\n",
    "           'WorkLifeBalance','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager']]\n",
    "\n",
    "# Converting strings to categorical values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "number = LabelEncoder()\n",
    "df2['Attrition'] = number.fit_transform(df2['Attrition'].astype('str'))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3855: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>...</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>College</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Female</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>Low</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>Below College</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>High</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>23</td>\n",
       "      <td>Very High</td>\n",
       "      <td>10</td>\n",
       "      <td>Better</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>College</td>\n",
       "      <td>Other</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Male</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7</td>\n",
       "      <td>Better</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>Master</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>High</td>\n",
       "      <td>8</td>\n",
       "      <td>Better</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Below College</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>Very High</td>\n",
       "      <td>6</td>\n",
       "      <td>Better</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Attrition     BusinessTravel              Department  \\\n",
       "0   41          1      Travel_Rarely                   Sales   \n",
       "1   49          0  Travel_Frequently  Research & Development   \n",
       "2   37          1      Travel_Rarely  Research & Development   \n",
       "3   33          0  Travel_Frequently  Research & Development   \n",
       "4   27          0      Travel_Rarely  Research & Development   \n",
       "\n",
       "   DistanceFromHome      Education EducationField EnvironmentSatisfaction  \\\n",
       "0                 1        College  Life Sciences                  Medium   \n",
       "1                 8  Below College  Life Sciences                    High   \n",
       "2                 2        College          Other               Very High   \n",
       "3                 3         Master  Life Sciences               Very High   \n",
       "4                 2  Below College        Medical                     Low   \n",
       "\n",
       "   Gender  HourlyRate          ...          NumCompaniesWorked OverTime  \\\n",
       "0  Female          94          ...                           8      Yes   \n",
       "1    Male          61          ...                           1       No   \n",
       "2    Male          92          ...                           6      Yes   \n",
       "3  Female          56          ...                           1      Yes   \n",
       "4    Male          40          ...                           9       No   \n",
       "\n",
       "  PercentSalaryHike RelationshipSatisfaction  TotalWorkingYears  \\\n",
       "0                11                      Low                  8   \n",
       "1                23                Very High                 10   \n",
       "2                15                   Medium                  7   \n",
       "3                11                     High                  8   \n",
       "4                12                Very High                  6   \n",
       "\n",
       "   WorkLifeBalance YearsAtCompany  YearsInCurrentRole YearsSinceLastPromotion  \\\n",
       "0              Bad              6                   4                       0   \n",
       "1           Better             10                   7                       1   \n",
       "2           Better              0                   0                       0   \n",
       "3           Better              8                   7                       3   \n",
       "4           Better              2                   2                       2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing numeric categorical features data with categorical values\n",
    "\n",
    "grade = {\"Education\":{1: \"Below College\", 2:\"College\", 3:\"Bachelor\", 4:\"Master\", 5:\"Doctor\"},\n",
    "       \"EnvironmentSatisfaction\":{1: \"Low\", 2:\"Medium\", 3:\"High\", 4:\"Very High\"},\n",
    "       \"JobInvolvement\":{1:\"Low\", 2:\"Medium\", 3:\"High\", 4:\"Very High\"}, \n",
    "       \"JobSatisfaction\":{1:\"Low\", 2:\"Medium\", 3:\"High\", 4:\"Very High\"},  \n",
    "       \"RelationshipSatisfaction\":{1:\"Low\", 2:\"Medium\", 3:\"High\", 4:\"Very High\"},\n",
    "       \"WorkLifeBalance\":  {1: \"Bad\", 2:\"Good\", 3:\"Better\", 4:\"Best\"},\n",
    "      }\n",
    "df2.replace(grade, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>...</th>\n",
       "      <th>OverTime_No</th>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <th>RelationshipSatisfaction_High</th>\n",
       "      <th>RelationshipSatisfaction_Low</th>\n",
       "      <th>RelationshipSatisfaction_Medium</th>\n",
       "      <th>RelationshipSatisfaction_Very High</th>\n",
       "      <th>WorkLifeBalance_Bad</th>\n",
       "      <th>WorkLifeBalance_Best</th>\n",
       "      <th>WorkLifeBalance_Better</th>\n",
       "      <th>WorkLifeBalance_Good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>5993</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>5130</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2090</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>2909</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>3468</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Attrition  DistanceFromHome  HourlyRate  MonthlyIncome  \\\n",
       "0   41          1                 1          94           5993   \n",
       "1   49          0                 8          61           5130   \n",
       "2   37          1                 2          92           2090   \n",
       "3   33          0                 3          56           2909   \n",
       "4   27          0                 2          40           3468   \n",
       "\n",
       "   NumCompaniesWorked  PercentSalaryHike  TotalWorkingYears  YearsAtCompany  \\\n",
       "0                   8                 11                  8               6   \n",
       "1                   1                 23                 10              10   \n",
       "2                   6                 15                  7               0   \n",
       "3                   1                 11                  8               8   \n",
       "4                   9                 12                  6               2   \n",
       "\n",
       "   YearsInCurrentRole          ...           OverTime_No  OverTime_Yes  \\\n",
       "0                   4          ...                     0             1   \n",
       "1                   7          ...                     1             0   \n",
       "2                   0          ...                     0             1   \n",
       "3                   7          ...                     0             1   \n",
       "4                   2          ...                     1             0   \n",
       "\n",
       "   RelationshipSatisfaction_High  RelationshipSatisfaction_Low  \\\n",
       "0                              0                             1   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              1                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   RelationshipSatisfaction_Medium  RelationshipSatisfaction_Very High  \\\n",
       "0                                0                                   0   \n",
       "1                                0                                   1   \n",
       "2                                1                                   0   \n",
       "3                                0                                   0   \n",
       "4                                0                                   1   \n",
       "\n",
       "   WorkLifeBalance_Bad  WorkLifeBalance_Best  WorkLifeBalance_Better  \\\n",
       "0                    1                     0                       0   \n",
       "1                    0                     0                       1   \n",
       "2                    0                     0                       1   \n",
       "3                    0                     0                       1   \n",
       "4                    0                     0                       1   \n",
       "\n",
       "   WorkLifeBalance_Good  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dummy variables on categorical data for easy interpretation\n",
    "\n",
    "final_data = pd.get_dummies(df2, columns =['BusinessTravel', 'Department', 'Education', 'EducationField', 'EnvironmentSatisfaction',\n",
    "                                     'Gender', 'JobInvolvement', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', \n",
    "                                     'RelationshipSatisfaction', 'WorkLifeBalance'])\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Age</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>...</th>\n",
       "      <th>OverTime_No</th>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <th>RelationshipSatisfaction_High</th>\n",
       "      <th>RelationshipSatisfaction_Low</th>\n",
       "      <th>RelationshipSatisfaction_Medium</th>\n",
       "      <th>RelationshipSatisfaction_Very High</th>\n",
       "      <th>WorkLifeBalance_Bad</th>\n",
       "      <th>WorkLifeBalance_Best</th>\n",
       "      <th>WorkLifeBalance_Better</th>\n",
       "      <th>WorkLifeBalance_Good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>5993</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>5130</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2090</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>2909</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>3468</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition  Age  DistanceFromHome  HourlyRate  MonthlyIncome  \\\n",
       "0          1   41                 1          94           5993   \n",
       "1          0   49                 8          61           5130   \n",
       "2          1   37                 2          92           2090   \n",
       "3          0   33                 3          56           2909   \n",
       "4          0   27                 2          40           3468   \n",
       "\n",
       "   NumCompaniesWorked  PercentSalaryHike  TotalWorkingYears  YearsAtCompany  \\\n",
       "0                   8                 11                  8               6   \n",
       "1                   1                 23                 10              10   \n",
       "2                   6                 15                  7               0   \n",
       "3                   1                 11                  8               8   \n",
       "4                   9                 12                  6               2   \n",
       "\n",
       "   YearsInCurrentRole          ...           OverTime_No  OverTime_Yes  \\\n",
       "0                   4          ...                     0             1   \n",
       "1                   7          ...                     1             0   \n",
       "2                   0          ...                     0             1   \n",
       "3                   7          ...                     0             1   \n",
       "4                   2          ...                     1             0   \n",
       "\n",
       "   RelationshipSatisfaction_High  RelationshipSatisfaction_Low  \\\n",
       "0                              0                             1   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              1                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   RelationshipSatisfaction_Medium  RelationshipSatisfaction_Very High  \\\n",
       "0                                0                                   0   \n",
       "1                                0                                   1   \n",
       "2                                1                                   0   \n",
       "3                                0                                   0   \n",
       "4                                0                                   1   \n",
       "\n",
       "   WorkLifeBalance_Bad  WorkLifeBalance_Best  WorkLifeBalance_Better  \\\n",
       "0                    1                     0                       0   \n",
       "1                    0                     0                       1   \n",
       "2                    0                     0                       1   \n",
       "3                    0                     0                       1   \n",
       "4                    0                     0                       1   \n",
       "\n",
       "   WorkLifeBalance_Good  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the reponse variable \"Attrition\" to the front of the table\n",
    "\n",
    "front = final_data['Attrition']\n",
    "final_data.drop(labels=['Attrition'], axis=1, inplace = True)\n",
    "final_data.insert(0, 'Attrition', front)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  <class 'numpy.ndarray'> (1470, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Defining the first parameter \n",
    "\n",
    "X = final_data.iloc[:, 1:65].values\n",
    "print(\"X: \", type(X), X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  <class 'numpy.ndarray'> (1470,)\n"
     ]
    }
   ],
   "source": [
    "# Defining the second parameter \n",
    "\n",
    "y = final_data.iloc[:, 0].values\n",
    "print(\"y: \", type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1233\n",
       "1     237\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Base Line Model using 'L2' regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "# Stratify parameter makes a split so that proportion of values in the sample produced will be same as proportion of values\n",
    "# provided to parameter stratify.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50, stratify=y)\n",
    "\n",
    "# Build the Logistic Regression Model using default 'L2' regularization\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Test] Accuracy score: 0.872282608696\n",
      "\n",
      "\n",
      "[Training] Accuracy score: 0.895644283122\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy from the testing data.\n",
    "y_predict_test = classifier.predict(X_test)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score:\" ,accuracy_score(y_predict_test, y_test))\n",
    "\n",
    "# Print the accuracy from the training data.\n",
    "y_predict_train = classifier.predict(X_train)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score:\" ,accuracy_score(y_predict_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I will dive more deeply and evaluate the performance of binary classifiers by computing a confusion matrix and generating a classification report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[298,  11],\n",
       "       [ 36,  23]], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# confusion matrix for test data using default 'L2' regularization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict_test)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Confusion matrix for test data using 'L2' regularization tells us that 298+23 are correct predictions and 36+11 are incorrect predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       924\n",
      "          1       0.82      0.46      0.58       178\n",
      "\n",
      "avg / total       0.89      0.90      0.88      1102\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       309\n",
      "          1       0.68      0.39      0.49        59\n",
      "\n",
      "avg / total       0.86      0.87      0.86       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report using 'L2' regularization \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_train, y_predict_train))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From above Classification Report, we find that training performance metrics are--as expected--slightly better than their test set counterpart in terms of accuracy score.*\n",
    "\n",
    "*But at the same time, we also notice that the recall for the positive class is constantly below 50%, which is not significantly good.*\n",
    "\n",
    "*Overall from the analysis report, we see that the result of minority class is not very good and this is probably due to the fact that there is an imbalance in the classes where one class is very large than other.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Base Line Model using 'L1' regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Logistic Regression Model using 'L1' regularization\n",
    "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "classifier_1 = LogisticRegression(penalty = 'l1')\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "classifier_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Test] Accuracy score: 0.872282608696\n",
      "\n",
      "\n",
      "[Training] Accuracy score: 0.893829401089\n"
     ]
    }
   ],
   "source": [
    "# Checking the model's accuracy from the testing data.\n",
    "y_predict_test_1 = classifier_1.predict(X_test)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score:\" ,accuracy_score(y_predict_test_1, y_test))\n",
    "\n",
    "# Checking the model's accuracy from the training data.\n",
    "y_predict_train_1 = classifier_1.predict(X_train)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score:\" ,accuracy_score(y_predict_train_1, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[298,  11],\n",
       "       [ 36,  23]], dtype=int64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data using 'L1' regularization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict_test_1)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Confusion matrix for test data using 'L1' regularization tells us that 298+23 are correct predictions and 36+11 are incorrect predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       924\n",
      "          1       0.82      0.44      0.57       178\n",
      "\n",
      "avg / total       0.89      0.89      0.88      1102\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       309\n",
      "          1       0.68      0.39      0.49        59\n",
      "\n",
      "avg / total       0.86      0.87      0.86       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report using 'L1' regularization \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_train, y_predict_train_1))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, y_predict_test_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From above Classification Report, we find that training performance metrics are--as expected--slightly better than their test set counterpart in terms of accuracy score.*\n",
    "\n",
    "*But at the same time, we also notice that the recall for the positive class is constantly below 50%, which is not significantly good.*\n",
    "\n",
    "*Overall from the analysis report, we see that the result of minority class is not very good and this is probably due to the fact that there is an imbalance in the classes where one class is very large than other.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV in scikit-learn using 'L2' regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.001, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "# Trying to estimate how this model will predict on unseen data by tuning the model\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "param_grid = dict(C=Cs)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "classifier_gcv = LogisticRegression()\n",
    "grid = GridSearchCV(classifier_gcv, param_grid, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the trainng data.\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.83938, std: 0.00205, params: {'C': 0.001},\n",
       " mean: 0.86298, std: 0.01018, params: {'C': 0.1},\n",
       " mean: 0.86751, std: 0.00902, params: {'C': 1},\n",
       " mean: 0.86570, std: 0.00937, params: {'C': 10},\n",
       " mean: 0.86661, std: 0.01164, params: {'C': 100}]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867513611615245\n",
      "{'C': 1}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872282608696\n"
     ]
    }
   ],
   "source": [
    "classifier_gcv_1 = LogisticRegression(C=1)\n",
    "classifier_gcv_1.fit(X_train, y_train)\n",
    "print(accuracy_score(classifier_gcv_1.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       924\n",
      "          1       0.82      0.46      0.58       178\n",
      "\n",
      "avg / total       0.89      0.90      0.88      1102\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       309\n",
      "          1       0.68      0.39      0.49        59\n",
      "\n",
      "avg / total       0.86      0.87      0.86       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report using 'L2' regularization \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_train, classifier_gcv_1.predict(X_train)))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, classifier_gcv_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hyperparameter Tuning using GridSearchCV in scikit-learn using 'L1' regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.001, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "# Trying to estimate how this model will predict on unseen data by tuning the model\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "param_grid = dict(C=Cs)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "classifier_1_gcv = LogisticRegression(penalty = 'l1')\n",
    "grid_1 = GridSearchCV(classifier_1_gcv, param_grid, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the trainng data.\n",
    "grid_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.83848, std: 0.00108, params: {'C': 0.001},\n",
       " mean: 0.85209, std: 0.01038, params: {'C': 0.1},\n",
       " mean: 0.87114, std: 0.00522, params: {'C': 1},\n",
       " mean: 0.86116, std: 0.01113, params: {'C': 10},\n",
       " mean: 0.85935, std: 0.00902, params: {'C': 100}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8711433756805808\n",
      "{'C': 1}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid_1.best_score_)\n",
    "print(grid_1.best_params_)\n",
    "print(grid_1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872282608696\n"
     ]
    }
   ],
   "source": [
    "classifier_1_gcv_1 = LogisticRegression(penalty = 'l1', C=1)\n",
    "classifier_1_gcv_1.fit(X_train, y_train)\n",
    "print(accuracy_score(classifier_1_gcv_1.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       924\n",
      "          1       0.82      0.44      0.57       178\n",
      "\n",
      "avg / total       0.89      0.89      0.88      1102\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.93       309\n",
      "          1       0.68      0.39      0.49        59\n",
      "\n",
      "avg / total       0.86      0.87      0.86       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report using 'L1' regularization \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_train, classifier_1_gcv_1.predict(X_train)))\n",
    "\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, classifier_1_gcv_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance for a logistic regression model using 'L2' regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Coefficient\n",
      "OverTime_Yes                           1.105801\n",
      "JobInvolvement_Low                     0.965035\n",
      "MaritalStatus_Single                   0.874477\n",
      "EnvironmentSatisfaction_Low            0.869302\n",
      "RelationshipSatisfaction_Low           0.850258\n",
      "JobSatisfaction_Low                    0.761273\n",
      "BusinessTravel_Travel_Frequently       0.669466\n",
      "JobRole_Sales Representative           0.650355\n",
      "WorkLifeBalance_Bad                    0.648171\n",
      "JobRole_Laboratory Technician          0.575997\n",
      "EducationField_Technical Degree        0.521560\n",
      "Education_Bachelor                     0.342879\n",
      "JobRole_Human Resources                0.320819\n",
      "EducationField_Marketing               0.302172\n",
      "Gender_Male                            0.296724\n",
      "EducationField_Human Resources         0.279759\n",
      "Department_Human Resources             0.268402\n",
      "Department_Sales                       0.222793\n",
      "NumCompaniesWorked                     0.194319\n",
      "YearsSinceLastPromotion                0.154059\n",
      "JobSatisfaction_High                   0.130657\n",
      "WorkLifeBalance_Good                   0.114052\n",
      "BusinessTravel_Travel_Rarely           0.101301\n",
      "JobInvolvement_Medium                  0.095263\n",
      "DistanceFromHome                       0.050782\n",
      "YearsAtCompany                         0.043137\n",
      "Education_College                      0.033602\n",
      "Education_Master                       0.024474\n",
      "HourlyRate                             0.003387\n",
      "MonthlyIncome                         -0.000049\n",
      "...                                         ...\n",
      "TotalWorkingYears                     -0.046968\n",
      "JobSatisfaction_Medium                -0.049474\n",
      "Age                                   -0.051411\n",
      "Education_Below College               -0.067336\n",
      "YearsWithCurrManager                  -0.090638\n",
      "YearsInCurrentRole                    -0.097716\n",
      "JobRole_Research Director             -0.127463\n",
      "EnvironmentSatisfaction_Medium        -0.151773\n",
      "Gender_Female                         -0.156111\n",
      "RelationshipSatisfaction_High         -0.157447\n",
      "Education_Doctor                      -0.193006\n",
      "MaritalStatus_Married                 -0.204409\n",
      "RelationshipSatisfaction_Very High    -0.238129\n",
      "EducationField_Other                  -0.257240\n",
      "EducationField_Life Sciences          -0.265846\n",
      "EnvironmentSatisfaction_High          -0.274514\n",
      "EnvironmentSatisfaction_Very High     -0.302402\n",
      "JobInvolvement_High                   -0.313536\n",
      "RelationshipSatisfaction_Medium       -0.314069\n",
      "Department_Research & Development     -0.350582\n",
      "JobRole_Research Scientist            -0.356283\n",
      "JobRole_Sales Executive               -0.412796\n",
      "EducationField_Medical                -0.439793\n",
      "JobRole_Healthcare Representative     -0.479865\n",
      "MaritalStatus_Divorced                -0.529455\n",
      "WorkLifeBalance_Better                -0.584350\n",
      "JobInvolvement_Very High              -0.606149\n",
      "BusinessTravel_Non-Travel             -0.630154\n",
      "JobSatisfaction_Very High             -0.701842\n",
      "OverTime_No                           -0.965188\n",
      "\n",
      "[64 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "classifier_fi = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "classifier_fi.fit(X_train, y_train)\n",
    "# Using Scikit-Learn to find Coefficient with indices\n",
    "df_coefs = pd.DataFrame(classifier_fi.coef_[0], index= final_data.iloc[:, 1:65].columns, columns=['Coefficient'])\n",
    "# Sorting Coefficient in descending order\n",
    "df_sorted = df_coefs.sort_values('Coefficient', ascending= False)\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate and sort the positive and negative ones coefficients by absolute value\n",
    "\n",
    "# Function for seperating positive and negative Coefficient\n",
    "# Ref: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html \n",
    "\n",
    "def positive(value):\n",
    "    return max(value, 0)\n",
    "\n",
    "def negative(value):\n",
    "    return min(value, 0)\n",
    "# Map value of 'df_sorted' using input function 'positive'\n",
    "df_sorted['positive'] = df_sorted['Coefficient'].map(positive)\n",
    "# Map value of 'df_sorted' using input function 'negative'\n",
    "df_sorted['negative'] = df_sorted['Coefficient'].map(negative)\n",
    "# Get absolute value of negative coefficients \n",
    "df_sorted['negative_abs'] = df_sorted['negative'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverTime_Yes                    1.105801\n",
       "JobInvolvement_Low              0.965035\n",
       "MaritalStatus_Single            0.874477\n",
       "EnvironmentSatisfaction_Low     0.869302\n",
       "RelationshipSatisfaction_Low    0.850258\n",
       "Name: positive, dtype: float64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 positive coefficients\n",
    "df_positive_top_5 = df_sorted.nlargest(5,'positive')\n",
    "df_positive_top_5_filter = df_positive_top_5['positive']\n",
    "df_positive_top_5_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverTime_No                  0.965188\n",
       "JobSatisfaction_Very High    0.701842\n",
       "BusinessTravel_Non-Travel    0.630154\n",
       "JobInvolvement_Very High     0.606149\n",
       "WorkLifeBalance_Better       0.584350\n",
       "Name: negative_abs, dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 negative coefficients\n",
    "df_negative_top_5 = df_sorted.nlargest(5,'negative_abs')\n",
    "df_negative_top_5_filter = df_negative_top_5['negative_abs']\n",
    "df_negative_top_5_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance for a logistic regression model using 'L1' regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Coefficient\n",
      "OverTime_Yes                           1.355411\n",
      "MaritalStatus_Single                   1.074336\n",
      "EnvironmentSatisfaction_Low            1.069124\n",
      "JobRole_Sales Representative           1.025290\n",
      "JobInvolvement_Low                     1.023394\n",
      "RelationshipSatisfaction_Low           0.995030\n",
      "JobRole_Laboratory Technician          0.667987\n",
      "JobSatisfaction_Low                    0.634503\n",
      "JobRole_Human Resources                0.623780\n",
      "WorkLifeBalance_Bad                    0.605329\n",
      "BusinessTravel_Travel_Frequently       0.591885\n",
      "Education_Bachelor                     0.312237\n",
      "EducationField_Technical Degree        0.201384\n",
      "NumCompaniesWorked                     0.190719\n",
      "YearsSinceLastPromotion                0.145296\n",
      "DistanceFromHome                       0.049682\n",
      "YearsAtCompany                         0.032514\n",
      "HourlyRate                             0.002667\n",
      "EnvironmentSatisfaction_Medium         0.000000\n",
      "WorkLifeBalance_Good                   0.000000\n",
      "Gender_Male                            0.000000\n",
      "JobInvolvement_Medium                  0.000000\n",
      "JobSatisfaction_High                   0.000000\n",
      "JobRole_Manager                        0.000000\n",
      "MaritalStatus_Married                  0.000000\n",
      "Education_Master                       0.000000\n",
      "EducationField_Marketing               0.000000\n",
      "Education_College                      0.000000\n",
      "BusinessTravel_Travel_Rarely           0.000000\n",
      "Department_Human Resources             0.000000\n",
      "...                                         ...\n",
      "JobRole_Manufacturing Director         0.000000\n",
      "MonthlyIncome                         -0.000034\n",
      "RelationshipSatisfaction_Very High    -0.000607\n",
      "PercentSalaryHike                     -0.014050\n",
      "EnvironmentSatisfaction_High          -0.016422\n",
      "Education_Below College               -0.026820\n",
      "EnvironmentSatisfaction_Very High     -0.044236\n",
      "TotalWorkingYears                     -0.045366\n",
      "RelationshipSatisfaction_Medium       -0.047896\n",
      "Age                                   -0.050792\n",
      "WorkLifeBalance_Best                  -0.056709\n",
      "Education_Doctor                      -0.069171\n",
      "JobSatisfaction_Medium                -0.082200\n",
      "YearsInCurrentRole                    -0.083829\n",
      "YearsWithCurrManager                  -0.085919\n",
      "JobRole_Research Director             -0.115904\n",
      "JobRole_Research Scientist            -0.124188\n",
      "MaritalStatus_Divorced                -0.267372\n",
      "Department_Research & Development     -0.326154\n",
      "Gender_Female                         -0.408225\n",
      "JobInvolvement_High                   -0.415559\n",
      "EducationField_Life Sciences          -0.452486\n",
      "JobRole_Healthcare Representative     -0.475948\n",
      "EducationField_Other                  -0.519949\n",
      "EducationField_Medical                -0.625370\n",
      "WorkLifeBalance_Better                -0.651207\n",
      "BusinessTravel_Non-Travel             -0.677771\n",
      "OverTime_No                           -0.708129\n",
      "JobInvolvement_Very High              -0.733655\n",
      "JobSatisfaction_Very High             -0.785793\n",
      "\n",
      "[64 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "classifier_fi_1 = LogisticRegression(penalty = 'l1')\n",
    "# Fit the model on the trainng data.\n",
    "classifier_fi_1.fit(X_train, y_train)\n",
    "# Using Scikit-Learn to find Coefficient with indices\n",
    "df_coefs_1 = pd.DataFrame(classifier_fi_1.coef_[0], index= final_data.iloc[:, 1:65].columns, columns=['Coefficient'])\n",
    "# Sorting Coefficient in descending order\n",
    "df_sorted_1 = df_coefs_1.sort_values('Coefficient', ascending= False)\n",
    "print(df_sorted_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate and sort the positive and negative ones coefficients by absolute value\n",
    "\n",
    "# Function for seperating positive and negative Coefficient\n",
    "# Ref: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html \n",
    "\n",
    "def positive(value):\n",
    "    return max(value, 0)\n",
    "\n",
    "def negative(value):\n",
    "    return min(value, 0)\n",
    "# Map value of 'df_sorted' using input function 'positive'\n",
    "df_sorted_1['positive'] = df_sorted_1['Coefficient'].map(positive)\n",
    "# Map value of 'df_sorted_1' using input function 'negative'\n",
    "df_sorted_1['negative'] = df_sorted_1['Coefficient'].map(negative)\n",
    "# Get absolute value of negative coefficients \n",
    "df_sorted_1['negative_abs'] = df_sorted_1['negative'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverTime_Yes                    1.355411\n",
       "MaritalStatus_Single            1.074336\n",
       "EnvironmentSatisfaction_Low     1.069124\n",
       "JobRole_Sales Representative    1.025290\n",
       "JobInvolvement_Low              1.023394\n",
       "Name: positive, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 positive coefficients\n",
    "df_pve_top_5 = df_sorted_1.nlargest(5,'positive')\n",
    "df_pve_top_5_filter = df_pve_top_5['positive']\n",
    "df_pve_top_5_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobSatisfaction_Very High    0.785793\n",
       "JobInvolvement_Very High     0.733655\n",
       "OverTime_No                  0.708129\n",
       "BusinessTravel_Non-Travel    0.677771\n",
       "WorkLifeBalance_Better       0.651207\n",
       "Name: negative_abs, dtype: float64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 negative coefficients\n",
    "df_nve_top_5 = df_sorted_1.nlargest(5,'negative_abs')\n",
    "df_nve_top_5_filter = df_nve_top_5['negative_abs']\n",
    "df_nve_top_5_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the above feature importance analysis report, we see that features like OverTime_Yes, JobInvolvement_Low with the high positive coefficients (towards attrition) makes some sense and are somewhat correlated to the things which influence employees to leave the company in short duration of time.*\n",
    "\n",
    "*On the other hands, we also see that the features like OverTime_No, JobSatisfaction_Very High, JobInvolvement_Very High with high (absolute value) negative coefficients (towards non-attrition) makes sense too and are somewhat correlated to the things which influence employees to stay at the company for the longer duration of time.*\n",
    "\n",
    "*In short, we can say that model has good understandability.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Feature Importance\n",
    "\n",
    "**1.**The one with the negative coefficient having the highest absolute weighted value will contribute the most important    feature as belonging to class 0 (employees who have not left the company).\n",
    "\n",
    "**2.**The one with the positive coefficient having the highest absolute weighted value  will contribute the most important feature as belonging to class 1 (employees who have left the company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "From the above work done, I can say that we are able to build a logistic regression model with an accuracy of around 87%. Also, the training performance is better than test performance which does indicate that model is neither over-fitting nor erroneous.\n",
    "\n",
    "However, Class 1 (minority class) recall and F1 score are not so good when compared to Class 0 (majority) recall and F1 score. This means that Class 0 (majority class) data has overinfluenced the model.\n",
    "\n",
    "I also worked on finding feature importance which helped me with some top features with their weight and how much they influence the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Graph using Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "# Print the accuracy from the testing data.\n",
    "print('Random Forest Accuracy: {:.2f}'.format(accuracy_score(y_test, rf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy(CART): 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "# Print the accuracy from the testing data.\n",
    "print('Decision Tree Accuracy(CART): {:.2f}'.format(accuracy_score(y_test, dtree.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "# Print the accuracy from the testing data.\n",
    "print('AdaBoost Accuracy: {:.2f}'.format(accuracy_score(y_test, ada.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd8VFX6/98zk55JJ4Te4dCkg4ANKdKLuurqul97d9cK\nrmVta++6+1NXd11dt+Kuq6BIE0UFUZAucDChtxDSJ5l+7++PexNCSJmUmckk5/16+TK57XzmTrif\ne855zvNYdF1HoVAoFIqqWMMtQKFQKBQtD2UOCoVCoTgNZQ4KhUKhOA1lDgqFQqE4DWUOCoVCoTgN\nZQ4KhUKhOI2ocAtQhA4hhA5sB/yADiQAJcAtUsoNQWhvMzBBSlnU3NcOF0KI0cB1UsqbhRCjgN9I\nKX8W5DZ1IFNKeSKY7dTQ7tvAm1LKHxp4Xp3fuxAiBfiflHJiIMcrwoMyh7bH+VUfMkKIe4HfA+Oa\nuyEp5bDmvmYLYBDQBcA01KAaQ5iZAvyxoScF8L2nAWMacLwiDChzaMMIIaKAbkBBlW0PAhdjDDnu\nA26VUh4RQnQA3gT6AxrGG+Vr5lvgq8AZQDTwOTBfSumreOMFFgEvSSn/Y7bxDGCRUt4nhLgOuNVs\nLx+4XUq5SwjxLpAO9AY+kVLeV037jcCvMXpBueZ5u83zdGCA2fZy4NdSSq8QYoCpNQOwAa9JKd8R\nQkwwt5cBiRgPrueAsUASYAGuBw4AjwMpQoi/AO8Bf5BSDjbbLTHvQ1dgF/BzKaVDCDEDeNbUuhmY\nDJwtpdxX7TOdCbxmavAA90opV5m7HxNCjDW1Py+l/H9CiETgDaCfea9KgSuklFII8aX5vfY3j1lv\nfqZYoCOwQkp5ndnuLOAJ8zsoA24GLgU6AX8XQvyf+Xlq+57dwMfAUOAXZluZGM+XvwLtzM/wqZTy\nt8BfgHizxzAS8GH2jIQQ9wNXmdt+Aq6WUhajCDlqzqHt8YUQYosQ4giw29x2DYD5EDgDGGO+zS0B\n/mQe8zqwW0rZH6OXcaMQog/wMvCDlHIkMBzjQXB3tTbfBq4227ABVwJ/EkKch/EgOEdKORzj4fVh\nlfMSpJSDajCGicACjF7QUOAfwEdCCIt5yFCMB/BA87+bTCP8D8Yw0EjgPOBe84ELMBi43LzeCIwH\n4zgp5UAME/iNlPIg8DDwtZTymhru7UhgGoYxdQIuEUJkAO8DV5r39Augc/UThRDRwEfA41LKwcAN\nwKtCiIp/o3tM3RcCL5rHTweKpJRjpZT9MB7Kt1e5bKGUcqCU8vfAHcDDUsozzXsyRwgxUgiRBfwN\n4yE8BHgeeEZK+SBwBPiFlPI76v6eY4DFUkpRbXjyBlP3COAcoK/5MnEN4JRSDpNS+qvcgzkYfyfj\nzHuwt9rnUYQQ1XNoe5xvvqENBz4D1kopj5v7ZmG8NW8QQoDxdp1g7puM8UDGfJMbDJVvnWPMHgBA\nfA1tLgReMHsfI4BsKeVPQogbgD7AWrM9gHQhRLr58ze1fIZpwL+llHmmnneFEK8CPcz970opHaa+\nvwLzgFUYvZB3qrQVj/Gg2wkclFLuN6/3rRDiIQxT6Q1MwHgrr4+lUkq32e42jLf5c4EdUsot5rXf\nE0K8VsO5ZwB+KeWn5nE/mNsw9f7DPG4zxtt/spTyP0KIPUKIX2HcxwnAt1Wu+XWVn68CZgghHsDo\nTSQAduAsYLuUcrPZ7oecatAV1Pc9f83pLAWWCCG6ASsxDLZYCJFWw7Fg/I19IKUsNLVUf8lQhBBl\nDm0UKeUmIcRdGG/w68whDhvwrJTyDQAhRCzG+DAY3fzKRFxCiF7ACfOcS6SUO83tqVWPM9sqE0J8\nAFyB0et429xlA96v6BmYb8mdgEJzv6MW+TX1eC0Ywx0VWqse6zfbKqo6vm2+NRdjDB85qmyfiTGE\n8iLGcMkujN5OfTir/Kybmnzm/6ui1XDuKffX1DHYbBvACyCl1E2zsAghbgFuBP6AYR4FQM8ql6h6\n/74GtmA8sBcCZ1bRV/V7tQBnSCm3VtNX3/d82nclpVwvhOiJ8dCfCHwvhJiH0SOpiepaUoHU6sNv\nitCghpXaMFLKf2K8ab5ibloGXC+ESDZ/fxxjSASMN7+K4acUjDHnvuY5dwkhLKaZLKLmoYCKoaXx\nwH/NbcuBy4UQHc3fbzavWx/LgMuEEJmmnmsw5iuyzf2XCSFihRBxGG/MiwEJuIQQV5rndMWI3BpZ\nw/WnYAyTVIzVz8N4OILxAIuu4ZzaWAP0E0IMMdu9GDjNQE19uhBiinncCIzeTl3/Rqdi9JL+bJ4/\nu4rOSsw39VHAfWbPoDNGT8MGfAcMEEIMMg+fizHMVP2zBvo9V233GeC3UsqPMIa1fsSYH/EBtirD\ngBWsBC6q8vf3KKcPUSpChDIHxe3AdCHEVIz5hU+AdUKIH4EhmHMF5nEDhBBbMR54T5tDH7/GmEDd\nBmw1//9c9UbMY33Af6WULnPbMoyJ2hXmda8ALpJS1pkqWEq5AmMMfJWp8ypglpSy4o28HONNeZv5\n/79IKT0YD77rzbaWYzy41tTQxJvAeeZx3wI5QE+zZ/Mt0F8I8b+6NFbRWgBcDvxVCLER44HuMzVW\nPc4NXAQ8Yk7UvmneC08dl38BY+hrM4apbsR46FfXUAg8DWwUQmwA7sf4DvtIKXMxJpHfM69zN/Bz\n89SPgH8LIS4gwO+5Gq8Aw4QQ24ENGHMI/wSOmlp3mnMyFTqXYExWrzGH5ToAD9bThiJIWFTKbkVr\nwowa2i6lfCHcWgDMt+CHgEellOVmj+BToFN9JqhQhBM156BQBBEpZYkQwgOsF0J4MeYOLlXGoGjp\nqJ6DQqFQKE5DzTkoFAqF4jSUOSgUCoXiNCJmzsHn8+uFheX1H9gGSEtLQN0LA3UvTqLuxUnUvThJ\nZmZS9ZDhgIiYnkNU1Gnh220WdS9Oou7FSdS9OIm6F00nYsxBoVAoFKFDmYNCoVAoTkOZg0KhUChO\nQ5mDQqFQKE5DmYNCoVAoTkOZg0KhUChOI6jmIIQ40yxXWH37bCHEeiHEt2bBF4VCoVC0IIJmDkKI\nBRgpoOOqbY/GSLd8AUapxhvNoisKhUKhaEYcjqJGnxvMFdI5GPnp36+2fQBGmchCACHENxilFD8I\nohaFQqFoVaxdlcOeXcdP2aah49N8+Hxuhq5fxrDtX8IR2ajrB80cpJT/FUL0qGFXMkZpxgpKgZRA\nrpmZmdQMyloH6l6cRN2Lk6h7cZLWfi/2/XQCh8NDnN2G1+/F6/fi8/vocmQ/M1f+mS5Hd+OOjqv/\nQrUQjtxKJUDVby0JCKjvk5cXSI331k9mZpK6FybqXpxE3YuTtNZ74dV87Cs+wO6iHIqcOr4oP9v6\nf0GsR2PELifDc1wMXb2atLzjyN5n8Nbse3ixkW2Fwxx2An2FEOkYRcnPxSh3qFAoFA2ipqEVAKvN\niubXajijZVHm8uH2+us+yKKBRUO3+o2fzfLj0Z44iNIYvy6GcdskvsREyqPi+XDyVZSSwBedRpCW\nFNtobSEzByHEFYBdSvmWEOJujILlVuAdKeXhUOlQKBSthz27juModWNvwkMwnLi9fjRdx2qpkji1\nFjMAQLdi0aOwaBasmpeB+zdxwer/kH7sCP+46HZWDZ6G32o81tOA0f3bN1pbJFWC01tjN7ExtNYu\nc2NQ9+IkbfFe/O31bwG48tZxp2yPlHtx7+tr0GMczJmWxO7CbH4q3EOZ72Sq8fYJ7eiX2pt+aX3o\nl9abBJ+FwhXLKVq+lA47ttNN7sTm8+EZMxbHy3/A37ffaW00NmV3xNRzUCgUikhH13VOOAvYXZTN\n7sIcnH12QpSbhbuN/WmxqZyROdA0hN6kxaUC4C8vo/Cz5eSuXE7CkcMM2b6FxMJCtLR0Sh59AvfP\nfwGWRnlArShzUCgULZLa5hOqEglDSu+v2szGI7vwJ5xAS8xDj3ZW7tO1WKKKu3DZmWci0vqQEZeO\npcpD3l9eRtHKFRSuWIbmdGJLSqJrYiKJhYU4L7+Ssod/h56RERTdyhwUCkWLJJD5BHtSLL2aMK4e\nDEo9DnYXZiMLc/ipMIfjnIBO5k5/NLaSTljL22Erz8TisTOmfxZndepzyjX85eUUrVxumEJ5ORkl\nJViuuY7USVPwe70Ubd+Kd+z4oH4OZQ4KhaLFYk+KPW0+oaVR7i3np6I9yMIcdhdmc7Qst3JfnC0O\nqyMLW1km986aTCd7B6yW2hNT+MvLKfp8RaUpJGo6ffdmk/jjNkrnzMUVGwuxsUE3BlDmoFAogshf\n3t1Aaa6jUedG6eCzwPzX1zb4XJvNgt8fnGAb3epFiy/An5CHPzEPPbYYKkaCNBtWZya2skys5ZlY\nXCk4S72kJcXSJalTrdesbgpR8Qn0tVrJWLYYi9uNe9IUPOecF5TPUxvKHBQKRdAozXUQpev4GjFZ\n6rNAWXT4E0frFn+lGWgJJ9DiC8FiGo9mxerMMM2gHVZXGhb91PrVaUmxtYaUVjcFmz2JroMG0+nf\nfydqTw7+Dh1xPPksnllzm33CuT6UOSgUiqDis1j49X0TQtpmU0JZfZqPfSUH2V1oRBTtLd6PTzcW\nqlktVnomda0MLe2V0p0YW0yD2/A7nYYpLF+GVl6G1W6n3cWXkHr+JOI//hDbvr2U33gL5fc9iJ6U\n3KjP0VSUOSgUijaNpmscLD2MNM0gp2gvHs0LgAULXewdK82gd2pP4qMan6+oRlOYdxEd8k/gHX8W\nelwc7ksvxzdsBH7Rv7k+YqNQ5qBQtFECCRVtCDWlgmjskFIw0XSNo2W5phlkk120F6fPVbm/Q2IW\nIs1YeNY3tReJ0QlNbvM0U0hMpN1FP6Ndhw4kP3gf0T+spzx7N2W/ewYslrAbAyhzUCjaLM2deqKm\nVBA+i4WkLHuzXL+x6LrO8fK8ymii3UU5lHlPrkLOjM9gRPshphn0JiW2+bK5+p1OilatpHD5UrSy\nk6aQduZY7K+9TPxbr2Px+3HNuwjnbXc0W7vNgTIHhaIN05yhohVRRc/fGvwwy/o47jjBt0e2mvMG\n2RR7Ts4/pMamcGaHkfRLM1Yhp8elNXv7mstJ4eenm0LqxEnE/rCBpMnnYjt8CH/3HpQ++yLeiVOa\nXUNTUeagUDSBhauyWd+MQzNNIZDwzXSXj0Svka20KaGiNVFY6m5SFtCmUOQuZndhjvlfNvmuwsp9\nSdF2RrYfappBHzLjM05ZhdycaC4nRas+p2DZZ4YpJCSSceHFpE6cjC0+HgA9KQlrQT5ld8+n/I57\nwdze0lDmoFA0gfW7jof1odhQEr1apSk0d6hoXSGbzU2px2EuPMvmp8IccsvzKvclRMUzpvMwuid2\np19qbzomZgXNDCqo0RTmXUTqpCnYoqKIf+sNPBMn4x8wEN+QYeRv3BG0tBfNhTIHhaKJpCXFtoih\nlEDCN2vLYtrSKfc6yS7aY/QMinI47DhauS/WFsOgjP70S+uNSOtDZ3tHstqnhCQra6UpLF+K5nCc\nagrx8UR9/x1J8+8kauePuL/7lpK//hOgxRsDKHNQKBQtELffQ07RXnYX5iALszlYehi9osiNNYr+\naX3pm9YbkdabbkldsFlt9VyxedFcLoq+MHsKDgfWhATDFCZOxpaQgKWwgMSHfkP8+38BwHnlVZQ9\n9GhINTYVZQ4KRQ0EOpfQkoeUagpVbalZTL1+L3tL9ptmkMO+kgNoujE3YrPY6JXSwwwv7U2PlO5E\nW8Pz6KrRFOZeaPQUEoyQ16jvvyPl6suxnjiBb8BASp97Bd+ZY8Oitykoc1AoaiDQuYRQjrM3lJpC\nVVtKFlO/5md/6UFkgTFMtKd4Hz7NBxgLz7old0FUrkLuQWwjViE3J4YprKJw2Wf4HaU1mkIF/j59\n0OPicfz2cZw33wbR0WFS3TSUOSgUtdBS5hKaQkvJaqrpGodKj1SuQs4u3ovH76nc39nesdIM+qT2\nJD6qZUTwaG43RV98TuFS0xTi401TmIwtIdE4yOUi4dUX8Q0cjGf2XPT0DArWbYKY8BpaU1HmoFBU\nY+GqbPJLXGQkNz5NQnPRkFXMVpsVza9V/h7OISRd16usQs7hp6I9OH0ni9x0SGhfGVraN7UX9pjE\nsOisjUpTWPYZ/tJaTAGI/nIV9vvuJmrvHrwjRuKZNcdIkBfhxgDKHBSK06iYa2gJw0VNWcUcyiEk\nXdc57jxRuc5gd2EODm9Z5f52cekMzzyjcuFZSmx4ksnVh+Z2U/TlKgqXLjlpCnPmkTp5yimmYMnN\nxf7I/cR9+B90m43ym2+nfMH9Ic+cGkyUOSgUNZCRHMelE/vUf2AICHRoqCmZSBtDvrOwMh3F7sIc\nitzFlftSY1MY02FEZS3kjPj0kOlqDDWZQvrsuaRNueAUUwCw7dxB6uypWEuK8Y4YSenzr+I/Y0iY\nlAcPZQ4KhSIgit0lp6xCPuEqqNxnj06szE/UL6037ePbBX3hWXNw0hQ+w19actIUJl+ALbHmoS5/\nP4Fv6HDcs+bg+r9rwBbaMNpQocxBEXFUDTOtL2VE1XQRgdLZTB5XsWAsnIQ79NThKWNT3lbWH9tE\nTvG+yu3xUXEMaTeocuFZKFYhNyea203x6i8o+GxJvaZgcZSS8OyT6Il2yn/zENhsFP/n41Y1hFQT\nyhwUEUdDUlZUTRcRKFaLhdjolvE2GI7QU7ffw7a8H1mfu5kdBRJN17BgoW9qLwZl9Eek9aFLUqc6\nayG3VBpiCug6MZ8uxv7gAmxHj+AT/Sm/e4Ex2dzKjQGUOSgilIow0/rG2SM1XUSo8Wt+dhbsZn3u\nJrbm/VhZ7KZrUmdGZQ1jZPuhpMWlhlll4zFM4UsKln6Kv6QEa1wc6bPmGKZgPz2luPXAfuz330vs\nimXoMTGU3fsbyn99d6uIQgoUZQ6KJhGOrKRVew0rFu9g+8ZDtR4b7mGZloyma+wtPsD63E1sPL6l\nssZBu/gMRmcNY1TWMDokZoVZZdOo2RRmkzZ5ao2mAGDNPUb6uWdiKS/Hc855OJ59CX+fviFWHn6U\nOSiaRDiyklZdlbxjy5E6DaClrAhuSRxxHGN97iY25G6mwExtnRRtZ0KXsxiVNZweyV0jav6gJvxu\nN4UrllGwdAn+4uKATAGfD6Ki0LI64Lz6enyDBuP+2WVtYgipJpQ5KJpMuFcSt5RVwC2ZfGchP+Ru\nZn3uJo6UHQMgzhbLmR1GMjprOP3Seoc8eV0w0Dweir/6kr3LluAtLMISG0f6zNmkTandFCwF+ST+\n7hGsx3Mp+dtCsFgoe/SJECtveShzUChaKQ5PGRuPb2VD7slIoyiLjaHtBjGqw3AGZwwgxhaZeX+q\nU2EKBZ99erKnMGMWaRdMq72noOvE/vsf2B97CGt+Pr6Bg7EUFaKntew1GaFCmYMiYGqaXwjWkFKg\naSMcDg92e9uZJKwPt9/D1rwf2ZC7iR0Fuysjjfql9mZUh2EMzzyDhOiE+i8UIRimsNo0BbOnMGMW\nfS7/GUXu2s+z7ZbYF9xFzNpv0BMScDz6JM4bb4Eo9UisQN0JRcDUNL8QrKykgaaNSE6Jo0ffds3e\nfiRREWm0LXs73x/afFqk0aisYaTGpoRZZfOieT0Urz7dFNKmTMWWlER0chLUFsVWXk7qnKlYCwpw\nT5uJ46nn0Lp0De0HiACUOSgaRCjnFwKZSwh1yoiWgqZr7Cnez4bczTVEGg03I41a30S85q3SUygq\nwhIbe4op1IWlqBA9NQ3MnoKekopn+swQKY88lDkoWkVhm7bCYcdRNuRuPjXSKMbO+V3OZkr/s0j2\np0d8pFFNaF4PxV9/RcGSTypNIW36TNIvmFavKViPHSXxt/cTvWUTBavXQXw87p//IkTKIxdlDopW\nUdimNVNbpNHYDqMY1WEY/VKNSKPMjNbXi6rRFKbNIH3q9HpNAb+fuL+8TeJTv8PqKMU7agzWgny0\nzl1CIz7CCZo5CCGswOvAUMANXC+lzK6y/xfAPYAfeEdK+UawtCjqJ9zhqIpTqYg0Wp+7iT1VI40y\nBzMqa1irijSqCc3roeTrryj47FN8hYWVppA2dRpRSQGk+/7hB1Kvu4HoLZvQUlIpfeFVXFdeBdbI\nS/kRLoLZc5gHxEkpxwkhxgIvAnOr7H8BGAQ4gB1CiH9JKQuDqEehaNG4fG62ndjB+txN7KwaaZTW\nh9FZwxiWObhVRRrVhOb1UvL16pOmEBPTMFMA0DS46iqif/wR1yU/N+YXMjODK7wVEkxzOBtYCiCl\nXCeEGFVt/1YgBfABFqD21JommZn1dCPbEHXdi3cW/8iaLYcDvlahw027lDgyM5NYsXgHO7YcaQ6J\nTcLh8JBsaqqPSP678Gl+th7bwdf7v2fD4a24zdKZvdK6cXb30YzvOor0hMBzGkXqvdC8XnJXfM6h\n/3yIJz8fa2wsnS+aR+d5c4hOCSDSStchOxv6mmku3noLXC7iJk4k/PX8IpNgmkMyUFzld78QIkpK\n6TN/3w78AJQBH0opi+q7YGsbT20s9UXofLXxUIMmj9PssYzom0leXinbNx5qEfmI7PYYevRtV+93\nHonRShWRRutzN7Hp+NZTIo0mVos08pdBXllgny8i74XXS8k3X1Ow5BN8hQVGT2HqdNKmTicqOZki\nD7WHpJpY9+3Ffv+9xKz9hoKvv0fr1p3M8eONexFh9yMYNPaFIZjmUAJUVWWtMAYhxBBgJtATY1jp\nb0KIS6SUHwRRT5uiKXMIKh1FcDjsOMr6Y0ZOo0K38S5UEWk0qsMwuidFfk6jQKnZFKaRNnUGUckB\nDh95PCS8/hoJLz2HxeXCc+75wRXdxgimOawBZgMLzTmHbVX2FQNOwCml9AshjgNpQdQSUdQXWlpf\ngZvGhpyuXZVDaYmbpGQVrtpc5DsLKkNP64o0aitoXi8la0xTKKhiChdMJyqQ4SOT6G/XYJ9/J1G7\nJVpme0pf+X+4L/xZm02SFwyCaQ7/A6YIIdZizClcI4S4ArBLKd8SQvwR+EYI4QFygHeDqCWiaGqm\n08aGnFakq1BZTJtGqcfBpuNbWZ+7uU1GGtWE7vNRvOZrCj5dfNIULphmDB81wBQqiH/rDWw/7cZ5\nzfWUPfAwekrk1ppoqQTNHKSUGnBztc27qux/E3gzWO1HOnUNCwVzbDkpOZbxE3sH5dqtGZfPzdYT\nP7Ihd3MNkUbDzUij+HDLDDknTeETfAX5hilMmUratBkNMwVNI3rtN3jPPhcAx5PPYr39DnwjRwdJ\nuUItglMoGolP87GzYDcbcjefUj2tW1JnRmcNZ0TW0FaX0yhQDFP4xuwp5GOJjjZNYTpRDXzLt+3a\naSTJW7eWooUf4Z0wEa1TZ7ROnYOkXgHKHFoMVecZQp2moiIDakuIUmrpnBJplLuVMp8RaZRZJadR\nVivMaRQoNZlC6pSppDfCFCgvJ/Gl54h//TUsPh/umXPw9xPBEa44DWUOLYSq8wyhTlNR1RjUfMPp\n6LrOkbJjp0UaJcckcX7XsxmdNZxuSV3aTKRRTeg+H8VrTVPIb6IpADGfL8d+3z3YDuzH37Ubjqef\nx3PB9CAoV9SGMocWRDhTWKjw1dOpiDRan7uJo2W5AMTZ4hjbcVRl9TSrpW2nY9B9PkrWriF/yWJ8\nJ04YpjD5AtKnzSAqtfGTxFGbNmI9cpjyX91F2d0LIDGxGVUrAkGZQxgJ5VBSXcVz1HDSSU5GGm1i\nT/F+wIg0GpY5mFFZwxmU0b/NRRrVxGmmEBVF6uQppE+b2ThT8PmI/eBfRs3m6GjKf3UX7llz8fcf\n0PziFQGhzCGMhHIoqa45hbY+nFQRabQ+dxO7Cn6qjDQSaX0Y1YYjjWpC9/ko+XYN+Z9WN4UZRKU2\nbqlS1MYN2OffRfS2LTiKi3DefDvExipjCDPKHMJMSyue01aoiDRaf2wTW0/swFsZadSF0VnD2nSk\nUU3UaAqTppA+vfGmYCkpJvGpx4n7y5+w6Dquy67A9bOfN7NyRWMJyByEEIlAb4xVzglSyrKgqlIo\ngoCma+QU7WND7iY2Hd92eqRRh+FkJajsnVXRfT5K1q2l4JPFeE/kNYspAMQs+wz7Pb/GdjwXX99+\nOJ57Ge9Z5zSjckVTqdcchBCTgD8CNmA8sFUI8Qsp5fJgi2tN1JQSI5B5hprmCqw2K5pfa1D7bXVe\nQdf1U6qnqUijwDBM4VsKPl2EN880hYmTSZs+k+i0Zsh0o+tYS4opu/+3lN92B8TENP2aimYlkJ7D\nUxjptz+TUh4VQpwH/BNQ5tAAakqJEcg8Q3OtP2hr8wonKnMaqUijhlCzKUwibfqsppmC2038m3/A\ndfkv0du3xzNtBgXrt6JldWg+8YpmJRBzsEopjwlhLD6RUu6o+FnRMBo7v1B9riASUzOHglKPg43H\nt7KhlkijwRn9iVaRRjWi+/0nh4/yjp80hWkziU5Pb9K1o7/5CvuCu4jK/gnbkcM4nn0JQBlDCycQ\nczgkhJgF6EKIVOA24EBwZbUuFq7KJr/ERUZyw8qOqCyp9eP0uvj+2EbWH9vErsJTI41GZw1nqIo0\nqpOaTCHl/EmkT2+6KVjy8rA/+iBxH/wL3WLBed2NlN3/22ZSrgg2gZjDTcCrQFeM7KmrgBuCKaq1\nUTHX0NBQVZUltWaqRhpty9+Bx18l0qjDcEa2H0pKbIA1Adoohil8S8Eni6qYwkTSp89qsikAxKxc\nRtKtN2AtKsI7ZBiOF17BN2xEMyhXhIpAzGGolPLyqhuEEBcBHwZHUuskIzmOSyf2afB5KkuqQUWk\nUUX1tHKfE4CO9vYMzxxq5DRSkUb1ovv9lH63jvxPFuE9nlvFFGYSnZ7RbO34e/YCmw3Hk8/ivPZG\nsLWdmhWthVrNQQhxGRALPC6EeLjaOQ+gzEERZCoijdbnGjmNitxG1dmUmCQmdj2HUVnDGNlrACdO\nOMKstOVT3RSw2UiZMJH0Gc1kCmVlJL7wDO6Zs/GNGoO/d1/yN+6AeDWkF6nU1XNIxghdTQKq1t/z\nAQ8GU1RboK50FhW01fBTI9JoE+tzN3OsSqTRuI6jGZU17JRIIxWCWje630/p96Yp5FYxhekzic5o\nnp5CzLLh0MUGAAAgAElEQVTPsN9/L7ZDB7HlZFPy138aO5QxRDS1moOU8m3gbSHEJCnl5yHU1CYI\nJES1LYWflnoc/HB8CxuObWZviRlpZI1iWOYZjM4axiAVadQgajSF884nfcasZjMF6+FD2B9YQOxn\nn6BHRVF+xz2U3TW/Wa6tCD+BzDm4hRAfA3aMcp82oLuUskcwhbUF2no6C5fPxZY8o3pa1Uij/ml9\nGZU1jGHtBxMfpd4+G4KuaSeHj3KPmaYwwTSFds3WTvTab0i54hIs5WV4xo7H8dzLKhdSKyMQc/gT\n8CxwNfAaMB3YGERNEUtNq6Ah9MV7Wjq7C3P45vC6U3IadU/qyqgOw1SkUSPRNY3jX37Fvn/8O6im\nUIF3yDB8vfvgvP4m3D//BajhvVZHIObglFL+RQjRAyjECGP9IaiqIpSaVkFDYCuh2wIHSg6xaM9S\ndhbsBqB9fDtGdRjO6KxhtFeRRo1C17STw0fHTFM4dwLpM5vXFCzFRSQ++Ri+IcNwXXkV2O0UrfxK\nmUIrJhBzcAkh0gEJjJVSrjIT8SlqIJwFe1oqueV5fLJnGRuPbwWgf1pfZvaaQs/k7mpCuZHomkbp\n+u/IX/xxpSlkTZ1CwvkXEN2uGY1W14n98APsDz+ANe843jPH4frF/xmmoL67Vk0g5vAS8G/gImC9\nEOIXqJ6DIgAKXUV8tm8l3x7dgKZrdE/qypze0+if3jfc0iKWmkwh5dzzSJ8xi04DejVrWhVbzk/Y\nF9xDzNdfosfH43joUaPWgjKFNkG95iCl/EAI8R8ppS6EGAn0A7KDLy0yaEw1t9aeFqPMW87y/V+w\n+tAavJqPrIRM5vSaxtDMwaqn0EgMU/iegsUf4zl2FGw2ks85l4wZs4nObP4hOduOH0m74DwsHg/u\nSVNwPPMiWvcezd6OouVS1yK4TOBuoAB4GWN9gxNj7cNSICsUAls6janm1lrTYrj9Hr44+A0rD3yJ\n0+ciNTaFmT0v4MwOI7BZ1QrZxqBrGqUbvqdg8SI8R48E3RTQNLBa8Q8YiHv2PNwzZuOZNUf1Ftog\ndfUc/g6UAu2AGCHEEuB9IAG4KwTaIobGzDO0prQYPs3H2iPfs2TfSko9DhKjEriozyzO7TxOrU1o\nJKeZgtVK8tnnkj5zFjGZzf9SYTl+HPujD6InJRlZUy0WSt/4U7O3o4gc6jKH3lLK3kKIJOBb4Fbg\n98BLUkpPSNRFMHWtgG4tK581XeOH3C18smcZJ1wFxNhimN5jEpO6navWJzQSXdNwbFhP/icf4zlS\nYQrnkD5zdlBMAU0j7v13SXziUazFRXhHjASPRxXfUdRpDiUAUspSM1rpYinlt6GRFfnUtQI60lc+\n67rOj/m7WLRnKYcdR7FZbJzX5Sym9ZhIckxSuOVFJLqm4fhhA/mLPwqNKQC27dtImn8n0T+sR7Mn\nUfr087iuvl4lyVMAdZuDXuXnXGUMDac1roDOKdrHxzmfkVO8FwsWxnQYwcyeF9AuvulpntsiJ03h\nYzxHDhumcJZpCu2D9wJhyc0lbfpELG43rnkXUfb402gdOgatPUXkUZc5JAkhzgGsQKL5c+WslJTy\nq2CLU7QcDjuOsnjPUrad2AnAGe0GMLvXNDrb1QOlMeiahmPjBvIXhdYUcDjAbkfPyqJswYP4Bg3C\nO3FK8NpTRCx1mcMh4HHz58NVfgajVzExWKIULYcTzgI+2bOcDbmb0NHpndKDub1n0Du1R7ilRSQ1\nmsL4sw1TyApeAKD14AHsDy7AWlBA0aKlYLXi/NWdQWtPEfnUlZX1/Nr2KVo/JZ5Slu77nG8Of4df\n99PZ3pE5vaYxKKO/WqvQCAxT+MEYPjp8CCwWksefRfrMOUE1Bbxe4t96g8Tnn8JSXo5n/NlYiovQ\n09QwoKJuAlkhrWhDOH1OVh74ilUHv8bj99AuLp1ZvaYyMmtoZQ0FReDomoZj0w9GT+EUU5hNTFaH\noLYdtf47kubfRdSO7WgZGZQ++xLuSy9XaxYUAaHMQQGA1+9l9eG1LN/3BWW+cpJi7FzYewbjO40h\nyqr+TBpKjaYw7izSZwXfFABwOkm56gqsJ/JwXnkVZQ89it6MZUAVrZ+g/asXQliB14GhgBu4XkqZ\nXWX/aIy8TRbgGHCllNIVLD2KmvFrfr479gOf7l1BkbuY+Kg4ZveaxvldzybWpmLdG4phChuN4aND\nB0NrCrqO9dBBtC5dIT6e0pd+j5aahm9s64qYU4SGes1BCJEGPAf0Bi4BngfukVIW1nPqPCBOSjlO\nCDEWeBGYa17TArwN/ExKmS2EuB7ojpH5VRECdF1nc952Fu9ZSm55HtHWKKZ0m8CU7hNIjE4It7yI\noyZTSBo3noyZc4jpEPyegi37J7jsXlJ37KRwzXr05BQ802YEvV1F6yWQnsPbwHJgDEY6jaPA34CZ\n9Zx3NkYOJqSU64QQo6rs6wfkA3cJIQYDn0oplTGEiF0FP7EoZyn7Sw9itVg5q9OZzOg5mdTYlHBL\nizh0TcOxeRMFiz/CfdA0hbHjyJg1h5hQrBtwuUh49UUSfv8yeDz4LpgGThckq+9S0TQCMYeeUsq3\nhBC3mGkzHhRCbAngvGSguMrvfiFElJTSh5GvaTxwO0aG10+EEBuklKvqumBmZstZffvO4h9Zs+Uw\nhQ437VLiyMxMYsXiHezYcgQAh8NDsrk9GDTmujkF+/nH1o/YlrsLgHFdR3LZGbPplBTZORTD8Xeh\n6zoF333PwX99QNnevWC1kjnhXLpc8jMSunQOjYgVK+DWWyE7Gzp3ht//nth584hVE85Ay3peRCKB\nmINPCJGCuWJaCNEX0AI4rwSo+u1YTWMAo9eQLaXcaV5zKTAKqNMcmjNXfVP5auOhymysI/pmkpdX\nyvaNhypTZtjtMfTo2y4omjMzkxp03dyy4yzes4xNedsAGJDejzm9ptEtuQu4IM/Vcu5rQ2novWgq\nuq5Ttnkj+Ys+xn3wgNFTOHMcGbNmE9OxE2VAWSj06DqpC+4jas8enDfdRvl9D9CuZ6cW9W8knIT6\n76Il01iTDMQcHgG+BLoJIT4CxgHXBnDeGmA2sNCcc9hWZd8ewC6E6GNOUp8D/LkhwlsCNWVjbUkp\nMwpdRSzZu5J1x8xiO8ldmdtrOiK9T7ilRRyGKWwif9FHVUxhrDF81LFTaET4/URt3ohv5Ggja+or\nr2Px+/CdMTQ07SvaFIGYwwpgA3AmYANuklLmBnDe/4ApQoi1GBFJ1wghrgDs5jDVdcA/zMnptVLK\nTxv3EULH2lU5bNt8BLfXT2ddx2qx8LfXT6acainZVh3eMpbv+4LVh9fi03x0SGjP7N7TGNpukFrA\n1kAqTWHxx7gP7K80hfSZc4jtFCJTAKK2bcE+/06itm6hcNUa/P0H4B84KGTtK9oegZjDAYwH/d+k\nlOsCvbCUUgNurrZ5V5X9qzAmuSOGPbuO4/f40TCMITb61OyV4c626vK5zWI7q3H5XaTFpjKz5xTG\nqGI7DUbXdcq2bDZ6ChWmMGYs6bNCawoWRykJzz5J/NtvYtE0XBddgqZWNytCQCDmMBi4GHhSCNEZ\n+BeGUbTJUqE+CxxuRHGfYOLTfHxz5DuW7v2cUq+DxOgELu45i3NUsZ0G01JMASDmk0XYH1yA7egR\nfD174Xj2JbwTVEozRWgIpIZ0IfAn4E9mOOofgYcCOVcRXDRdY0PuZj7Zs5z8ymI7k81iO3HhlhdR\n1GwKZ5qmEKLoo2rErFiKNf8EZff+hvJf3w1x6jtVhI5AFsFlYix++zmQDvwDuDDIusJGXRXcSkvc\naKeUuQgPuq6z7cQOFuUs5UjZMWwWGxO6nMW0HpNIirGHW15Eoes6ZVu3GKawf59hCqPHkD5rLrGd\nQ2wKXi+xn3yMe97FYLFQ9vDvcP7qLvx9+oZWh0JBYG//m4GFwF1Syh+CrCfs1FXBzWuBAh1Gh3Fe\nIbtoL69tXY48kYMFC2d2GMnMnlPIUMV2GkSLMgUgat23JC24k6hdOymOisYzey56Rgb+DJUPSREe\nAjGHrubkcpuhtnDU+a+vBeDSiaEPBT3sOMqinM/Ynm/M6Q9pN4jZvabSyR6CJG6tCF3XKdu2xVin\nsG8vWCzYR40hY/YcYjt3CbkeS0E+ib97hPi//xUA5/9di/ecc0OuQ6GoTq3mIITYKKUcgbEIrupY\nigXQpZStMvylzOXD7fVXGkFVKha9hZITznyz2M5mdHT6pPbk6pE/I03PDKmOSMcwha1GT2HfXoCw\nmgJA7P/+g/2B+Vjz8/ENGETpC6/gG31mWLQoFNWpq9jPCPP/pyXxF0KEP5g/SLi9fjS95nmFtKTY\nkA0pFbvNYjtH1qHpGl3snZjTezoD0/vRvl2yWv0ZIDWbwmgyZs8NmylUYD2Rh8XpxPHokzhvuBmi\nVWSZouUQyIT0t1LKcVV+t2IsijsjmMLCidViCVuoqtPnZOX+1UaxHc1Lu/gMZveayoj2Q1SxnQag\n6zrl27eRv+gjXHv3AGAfOcowhS5dwyPK6ST+7TcNI4iPx3ntjbhnzkELUzSUQlEXdQ0rrQImmD9X\nnXPwAYuCK6vt4fF7+apKsZ3kmCQu6jmL8R3HqAVsDUDXdcp/NE1hTwsxBSB61QqS7rsH2/59oGs4\n77gHbDZlDIoWS13DShMBhBCvSinvCJ2k8LBwVTY5m4+QqhtRSaHCr/lZd2wDS/auNIvtxDO313Qm\ndD2LGFVsJ2BqNYVZc4ntGj5TsB47SuJv7yfu4w/RbTbKb/01zutuCpsehSJQ6uo5zJJSfgJsFEL8\nX/X9Usq/BlVZiFm/6zidPX7AQlJW8NcK6LrOprxtLN6zlOPlJ4i2RnNB9/OZ0u08ElSxnYDRdZ2y\niuGjPTkA2EeMJGP2vLCaApgTzvfeibW0BO+oMZQ+/wr+QYPDqkmhCJS65hxGA59gDi1VQwdalTmA\nMdeQlBTLlVePqv/gJrCr4Cc+zlnCgdLDWC1Wzu48luk9JqliOw3A6Cls5+hniymVu4EKU5hLbNdu\nYVZnoGV1AJuV0hdexXXlVWBVc0aKyKGuYaVHzP9fU7FNCJGMse7hxxBoa3XsKznAopylyEIjLdXI\n9kOZ1esC2ieosNRA0XWd8h0/Gj2FHOM+2oePJH32HOK6dQ+rNktpCQnPPY3z+pvQuvfAO/5sCjb+\niG5XRWcUkUcg0UrXAWcB9wGbgFIhxH+llA8FW1wwWbgqm/VV0mQUlrrpSnAmGw47jrJ4zzK2ndgB\nwMB0wZze0+iapCYjA6U2U+j9f5fjTGoXbnHELP4I+4P3Ycs9hsXlwvH8y8YuZQyKCCWQFdK3AlOA\nK4GPgTuAdRjJ9yKW9buOn7KoLS0plliXv1nbyC07zqd7V7Dx+FZ0dHqldGd2r2n0S+vdrO20Zmoy\nhcThI8iYPZe4bt2xZybhDOOaD+u+vdjvv5fYz1egx8ZStuAByn91V9j0KBTNRUCZVaWUBUKIGcBr\nUkqfECI+yLpCQvVKblUL9zSFfGcBS/at5LujP6Cj0zWpM7N7TWVgulDFdgJE13XKd+4wTCH7JwAS\nhw0nY868sA8fVRDz6WKSb7kOi8uF59zzcTz3Iv5eqsqeonUQiDn8KIT4BOgFrBRCLATWB1dW81F9\n+KiCYKTCKHIXs2zfKtYc+R6/7qdDYhaze17A0MzByhQCpFZTmD2XuO49wiuuGr7hI/B37ET5fQ/i\nvvBnoL5jRSsiEHO4FhgPbJNSeoQQ7wOfBVdW81F9+KiC5kyF4fCUsfzAF3x1aC1ezUe7+Axm9pzC\nqKxhalVzgOi6jnPXTvIXfYTzJyP6qKWZgiU/n8THf4t73sV4z5+E1qkzhWt/AJtapKhofQRiDjHA\nLOAlIUQU8AWwCmOldERQffiouXD6nHx+4CtWHfwat99DamwKM3pMZmzHUWpVc4DUaApDh5Exex5x\nPXqEV1wFmkbcv/5O4mMPYS0sxFpaivf8ScY+ZQyKVkog5vAHoByjB2EBbgDeBH4ZRF0tGrffw+qD\na1hx4EvKfU6Sou3M7jWNszudqcpyBkhEmAJg27UT+4K7iFm3Fi3RjuN3T6sVzoo2QSDmMFJKObTK\n77cLIXYES1BLxuv38s2R71i2bxWlXgcJZqqL87qeRaxKdREQuq7jlLsMU9gtAUgcMtSYaO7RM8zq\nTiX669WkXHYhFp8P98w5OJ58VuVCUrQZAjEHqxAiVUpZBCCESCWChpSaA7/mZ93RDSzZZ+Q/iq2s\n1XwO8VGtInArJJRX9BRauCmg62Cx4B0zFu855+G87kY8F0wPtyqFIqQEYg4vAeuFEBWZWOcATwdP\nUstB0zU25G7m070rOOHMJ9oazeRu5zGl2wTsMYnhlhcx1GgKs+cS17NXmJWdivXIYewP3od35Gic\nt98BsbEU//t/4ZalUISFes1BSvkXIcR64DzAClwkpdwWdGXNSLrLF9Aahora0bquszlvO5/sXc6x\nslxsFhvndh7PtB4TSYlNDoHi1kF5xfCRNEqbJp4xxOgptDBTwOcj/p23SHj6CaxlDixlDpy3/VqF\npiraNHVlZbUCtwH9gG+klP8vZKqamUSvhsNrPPjrPC4plpQeNp7d8BoHzaR44zqOZnqPyWTEp4VI\nbeRTkymkz55HfK8WZgpA1KYfsN97J9HbtqClpVH6xB9wXX6lMgZFm6eunsPrwEBgLfCAEEJIKR8P\njazmx54Uy5W3jqt1/+7CHBbvWca64n1YSi2MyhrGjJ5TyFJJ8QKmfLc0TGHXTgASBg8hY85c4nu1\nzHQhtp07SJ02EYuu47rsChyPPIHeLsx5mhSKFkJd5nAeMFBKqQshnsdY2xCx5lAbB0uP8FH2p+wq\nNFbjDmk3iFm9LqCzvWOYlUUOEWUKug4uF8TH4x8wEOdNt+GZOh3vWeeEW5lC0aKoyxxcUkodQEqZ\nL4TQQ6QpZDh9Ll7d9EecPicD0vsxu9dUuieHt0BMJHG6KZxBxuy5xPdumfmFrHtySPrNPWjpGZS+\n+WcAyh5/KsyqFIqWSV3mUN0MtBqPimC+ObwOp8/JjJ5TmNlzSrjlRAzOn3aTv+gjyncay10SBg0m\nY868FmsKuN0k/OEVEl55AYvbjef8SeB2Q2zz5tZSKFoTdZlDdyHEO7X9LqW8Nniygo9X8/HFwW+I\ntcVwfpezwy0nIog4UwCiv/kK+4K7iMr+CX/7LMqefBb3nAvVhLNCUQ91mcPd1X5fHUwhzcXaVTns\nMbOwlrl8dPb4iKqhiM/6Y5so9pQwqeu5JESrhWx14fzpJ9MUjAKACYMGG8NHffqGWVndWI4fJ+Xy\ni8HjwXndjZTd/1v0ZFWKVaEIhLrKhL4XSiHNxZ5dxyvXK7i9RvEeW4yNXlUysGq6xsoDq7FZbJzf\nVfUaasOZbZrCDtMUBg4yegot2RQ0DUteHnpWFnr79jiefQnfwEH4ho0ItzKFIqIIqNhPpFERtjr/\n9bUAp2Vk3XZiJ7nlxxnbYRRpcanhkNiiqdEUZs8jvm8LNgXAtuNHkubficXhoHDlVxAdjeuKNpsf\nUqFoEkEzB3MR3evAUMANXC+lzK7huLeAAinlb4KlpSq6rrNi/5cATO5+XiiajBicOdmGKfy4HYCE\nAYOMkNS+/cKsrB7Kykh84Rni3/wDFr8f15wLsZSXoaco41coGktA5iCESAR6A9uABCllWQCnzQPi\npJTjhBBjgReBudWuexNwBk2cz6g6z1AxpLRwVTb5JS4ykuNOOTaneB97S/ZzRrsBdEzMakqzrYaI\nNQWAxYtJv/U2bIcO4u/WA8czz+OZPDXcqhSKiKdecxBCTAL+CNgwKsJtFUL8Qkq5vJ5TzwaWAkgp\n1wkhRlW77njgTPPa/RuhvZKq8wz2pFh69W/P/3blApxW7a2i1zCl2/lNabJVcLopDCR99lwS+okw\nKwsQlwtuuw1r7jHK7ryX8jvvhYSEcKtSKFoFgfQcnsJ40H8mpTwqhDgP+CdQnzkkA8VVfvcLIaKk\nlD4hREfgEeBC4NJAxWZmJtW43Wqzkpwazx0PTa7ctuiJ5bRPi+e2y4ZXbjtYfITt+TsRGb0Y2/eM\nQJttkdR2LwKhVO7mwL8WUrRxEwApQ86g688vJWXQwOaSFzx8PtixA4YMAZLgb3/D0q4diQMHovLk\nNu3vorWh7kXTCKieg5TymBDG26SUckfFz/VQAlT9dqxSyoo6EJcA7YAlQAcgQQixS0r5bl0XzMsr\nrXG75tcoc/m4+rFlldsq6kZXPWfhjiUATOh0Tq3XigQyM5Mapd+5J8foKWw3kurG9x9Axpx5JPQT\neKj9/rYUojZ8T9L8u7AeOkjBmg3o7duTee65hu4Wrj0UNPbvojWi7sVJGmuSgZjDISHELEA3C/3c\nBhwI4Lw1wGxgoTnnUJnmW0r5GvAagBDiaqB/fcZQH26vn0KvjzQz82paUuwpQ0qFriLW526iQ0J7\nBrcb0JSmIg7DFD6mfPtWwDSF2XNJEE0azQsZlqJCEp98nLi/voNF13Fe8UuIbpWBdgpFiyGQf2E3\nAa8CXYE9wOfAjQGc9z9gihBiLUbt6WuEEFcAdinlW43UWydpSbGnha1WsOrg12i6xuRu52G1WIPR\nfIvDuWeP2VOITFNA14n98APsv70f64k8fKI/judfwTu25u9YoVA0H4EU+zkOXN7QC0spNeDmapt3\n1XDcuw29dkMp95az5sh3pMQkM6rD8PpPiHCce/ZQsPgjyraZptBPGMNH/SOvxxT3j/exlDlwPPQo\nzptvhxhVq1uhCAWBRCvt5fQkfEgpw165pSKE1VHqrvO4rw6vw+33MKPnFKKtrXc4wrV3D/mLP6Zs\n6xYgQk3B5SLm6y/xTJkGFgulL74GFgta9x7hVqZQtCkCeVJOqPJzNEaEUYtIZ1k1hPWgy1vjMR6/\nly8PfkN8VBxndTozxApDQ6swBSB69RfY77sb2949FC1ZiW/kaLQePcMtS6FokwQyrLS/2qbnhRAb\ngCeCI6lhVE+VUZ3vjv1AqdfBBd3PJz4qrsZjIhXXvr3kL/ropCn07UfG3AuJF/2xRFDWUcvx49gf\nvp+4Dz9At1px3nAz/khZa6FQtFICGVY6t8qvFmAQEPY0pmtX5VBa4iYpufbV0Jqu8fmB1URZbExo\nRWm5Hdk5HH7v76eawpx5xPcfEFGmABD3/rskPvZbrCXFeIcNx/HCq/iGDAu3LIWizRPIsNJjVX7W\ngRPAVcGREzgV6TLqWg29OW87ec58zuo0hpTYyF8Q49q3j/zFH1G2ZTMQ2aZQgW23BF2n9OkXcF19\nHdhs4ZakUCgIzBwWSinfCLqSRpCUHMv4ib35365cMpLjuHTiyaIzFQn2LFiY1C2yE+y59u8z5hQ2\nGyuakwb0J2XGnMg0BYeD+H/8Fef1N4PVStl9D+K8/Q60rA7hVqZQKKoQiDncBrRIc6iLn4pyOFB6\niGGZg8lKyAy3nEZR3RTi+vSl3dwL6XbOGE6ccIRZXcOJWfIJ9gfmYztyGC01Dfell4Pdjma3h1ua\nQqGoRiDmcFAIsQr4DnBWbJRSPh40Vc3A8oq03N0mhFVHY3Ad2G9MNFeYQu8+ZMy9kIQBA7FYLBHX\nW7AePID9wQXELl2CHh1N2d0LcM+eF25ZCoWiDgIxh3VVfo6Ip9LB0iPsLNhN39Re9EzpFm45AVOj\nKcyZR8LAQRFnCBXEvfcO9kcewFJejuesc3A89zL+SEgFrlC0cWo1ByHEVVLK96SUj9V2TEtl5YEv\nAZjSfUJYdQSK68B+Y/ho00agdZhCBXpcHHp8PKXPvmQMI0X451Eo2gp19RzuAFp0Hekyl4/5r6+t\nzMAKkO8sYOPxrXRK7MDA9JYdK+86sJ+CxYtwbPoBgLhevY3howg2BUthAQkvv0D5PQvQU1JxX3o5\nnmkzVFU2hSLCiOhcElUzsVaEsX5uJtib0n1Ci33Aug8eIH/Rx63KFNB1Yj/4F/ZHH8R64gR6Sgrl\n99wHFosyBoUiAqnLHAYJIfbUsN0C6C0htxKcmonV4Slj7ZHvSYtNZWT7oWFWdjrugwfIX/wxjo0V\nptCLjDkXkjBocOSaAmDL/gn7gruI+eYr9IQEHA//DudNt4ZblkKhaAJ1mUM2MCNUQpqD1YfX4tW8\nTOp2LjZry1lM5T58mPyPP6xmCvNIGHRGRJsCGFlT7QvuwuLx4J46HcdTz6N1jZwgAIVCUTN1mYOn\nhrxKYaeuTKxrj3xPfFQ84zqODoOymnEfOsiBp36H7vEQ17MXGXNbhylU4Bt8BlqHjjgefxrP9Jlq\nwlmhaCXUZQ5rQqaiAdSWidXpc1LkLmZghiAuqkUkjUVzOTny5v9D93jIuuZ6ksefFfGmYM09RuKj\nD1H+67vxDxiIb8gwCtZtgqiInr5SKBTVqLUkmpTy9lAKaQgVmVgL4k4+kPKc+QBkxrcLl6xT0HWd\n3Pffw3vsGKlTppJy1tmRbQx+P3HvvE3a+FHE/Xch8e/+6eQ+ZQwKRauj1fyrziuvMIeMMCsxKP5q\nNaXfrSOuV28yL74k3HKaRNTWzdjn30n0po1oySmUPvcyrl9eHW5ZCoUiiLQec3C2HHNwHdhP3j//\nhjUxkY433Yolgt+sYz/6L0k3X4dF03BddAmOx55Cz8oKtyyFQhFkah1WijTynCcAyEwI77CS3+nk\n6Juvo/t8dLjuBqIzwm9WDUbXjf8Az7kT8I0YRdEHH1P65p+VMTSRjRs38Mgj9zfpGu+//y47dmyv\ndf9///tvANatW8vHH38YkKZZs6Zw++038qtf3cS1117JQw/dh9dbc3XFUPHAA/ObfI3lyz9j9epV\nzaCmaWzfvo0bbriKW265lnfeeeu0/X6/n1deeYFbbrmW6677JWvWfA3A+vXfcd11v+TGG6/mrbde\nB8DtdvHEE4+g66dVb25WIveVthp55flYsJARlxY2Dbquk/veO3iP55I2bQb2CCxaY92/D/v99+K+\n7It8OJgAACAASURBVArccy9CT8+gaMnKcMsKCgtXZbPerAvSXIzu3/6U1PHB4Jf1DOm99947XHzx\nZYwdOz7ga44cOYrHHnu68vdHH32Qb75ZzfnnT26szCbz1FPPN+l8p9PJ0qWf8tJLf2gmRY3nhRee\n5sknn6NTp87Mn38Hu3fvol+//pX7ly1bgs/n44033iEv7zhffGH8m3v99Vd5+OEn6NGjJ7feej05\nOdn07t2HwYOHsHTpp0yfPitomiPGHFYs3sH2jYcqI5WqV3874TxBelwaUdbwfaTiLz7HsWG9kVp7\n3kVh09EovF7i3/g9iS8+i8XpRE9Nwz03wj5DBLN+/TreeusNYmNjSU5O4f77H8Zut/Pii88i5Q7S\n0zM4evQIzz77Mu+88xaTJl1Ap06defrpx7DZotA0jddee4W///3flJQU88ILzzBw4CD279/HLbf8\ninff/RNff70av9/PvHkXM2/exbVq8Xq95OefICkpGYA33/wDW7ZsQtM0LrvsF0ycOJkdO7bz0kvP\nkZCQQFpaGjExsVx77Y3cd99dJCenMG7cWYwdexavvPI8uq6TkpLC/fc/gtfr5ZFH7kfTNDweD/Pn\n30+3bj14+OHfUFZWhsvl4sYbb2XMmLHMmTOVRYuWsXv3Ll5++XlsNhsxMTEsWPAQuq7x6KMP0r59\nFocPH2LgwEHce++pPbLlyz9j9OixAJSVOXjmmSdwOEo5cSKPiy66lAsv/Bm3334jaWnplJSU8Pzz\nr/Dii89w6NBBNE3jhhtuYcSIUXzxxUo+/PADfD4fFouFp556gdTUk6v+//vff/PFF5+f0vZDDz1O\nhw4dKtv2ej107twFgDFjxrFhw/enmMN3331Lr169mT//DnRd5667FgDQt6+gpKQEn8+Hx+PBajUG\neyZOnMI99/xKmQPAji1HKo2hevU3t99DsaeU/ml9w6bPtW8feQv/hc2eRMcbb4moeYaodd+StOBO\nonbtRGuXSemLr+G++NJwywo6l07sE/S3/EDQdZ3nnnuK11//E5mZ7Vm48J+8996fGTp0GCUlxbz9\n9l8pLCzk/7d33uFRVF0cfje7m2Q32fQACaRQB6SJgCgiSBVFQFCqgkIkQgjSJPRqKIIoKCBdkKJG\nkCoqfCgoCCJNQGEg9BJCEtLLJtnd748NS0JIAdIW7vs8eWBn5t575mQzZ277nV69uuQo9/fff1Gr\nVm2Cgobyzz/HSExM5J13Ati4MYwPPxzDjh3bADh79gx//fUnS5euwmg0snjxAkwmU47Vc0eOHCY4\nOJC4uFgUCgWdOnWlUaNnOXBgPxER1/nyyxXo9Xref78fjRs34ZNPZjJhwjSqVKnKkiULiY6OAuD2\n7RhWrFiLWq0mMPBdxo6dROXKVdi+fTPr1q2mbt36ODk5M3HiVC5evEhqairXr18jPj6euXM/JzY2\nlqtXc26v+vjj6YwZM4Hq1SX++GMPCxZ8yuDBw7h69QqffbYAOzt7unfvTExMNO7ud4eVjx07QocO\nHQG4du0abdq0o0WLVkRHRxEcHEiXLm8C0KbNy7Ro0ZJNmzbg7OzC2LGTiI+PY/DgQNauDePq1SvM\nmTMfe3t7Zs+ezqFDB2jX7hVLO2+80YM33uiR5+83OTkZrdbB8lmr1XLjxvUc18THx3H9+jVmz57H\n8eNHmTFjKgsXLqNq1WqMHj0MJydnqlatjp+fPwBOTk7Ex8eRlJSEYzHlQ7GeJxh3l7ACObK/XU+K\nAMBDWzrj+4aUZCIWL8RkMFDhvUDUbm6lYsfDoP59Dy5vdsKkUJD6TgDJ4ydhcim9obknkbi4OLRa\nBzw9zfpgTz/dgCVLFuHs7EKdOnUBcHV1xdfXP0e5117rzLp1qxk5cggODo6MGXP/MforVy5Tq1Zt\nlEolSqWSIUOG57rmzrBSfHwcw4cPxsvLG4ALF8KR5TMEBwcCkJmZyc2bN4iOjqZKlaoA1K/fgN27\ndwLg5eWNWq0G4PLli8ydOwsAgyGTSpV8ee65ply7doUxY0aiUql4550AqlSpSufOXZkyZTyZmZm8\n+WbPHLZFR0dRvbqU1dYzLF5sHiaqWLGS5aHr7u5Benp6jnLx8XG4upqfCW5uboSFrWfv3t/Qah3I\nzMy0XOfr6wfA+fPhnDhxzDKfYzBkEhcXh6urG6Ghk9FqtVy+fIk6derlaKegnoODgwOpqSmWcykp\nKTg65kxb7OzsTNOm5uXuDRo05OrVKyQmJrJmzSrWrAnD07McixbN59tv19K7d9+se3InISFeBIf8\niErJmowuhZVKJpOJyK9WkhEdhVuHjjhk/TGXaUwmyMwEtZqMF14krUdvUt/pT2ajZ0vbsicSFxcX\nUlKSiY6OxsPDg+PHj+Lj40uVKlX55ZcddO8OCQkJXL16JUe5ffv2Ur9+A/r3D2TXrp9Zvnw5I0aM\nyzVR6efnz+bNGzEajRiNRj788ANmz56Hra1tLlucnV2YOPEjPvhgIDVrrsfPz58GDRoxevR4jEYj\nq1Ytp2LFSpQrV56LFy9QuXIV/v33pKW8QnF3jYuvr5/lIXnixHFiYqI5duwI7u4efPbZQk6dOsGS\nJQsZNmwUKSnJzJkzn+joaAYN6s8LL7xoqcfDw5Pw8HNUq1bd4htzW/nvG3J1dSMpKRGAb79dS506\n9ejS5U2OHj3MgQP7LNfdGarx8/OnXLly9O3bH70+jdWrV6JSqVixYgkbN24HYPjwwbn8W1DPwcHB\nEZVKzfXr1/D2rsihQwfo1y8wxzX16j3NgQP7eeml1pw7d5by5ctjZ2eHRqNFo9EC5gAYFxdnKZOU\nlIhLMb7IPR7BoRQ3wMXt3kXSsSNoaki4dyr72c2U8hkcQ4aT0eR5UsZNAqWSxC8Wl7ZZTxSHDplX\noNxh8uRQQkLGM378KGxsFOh0TowbNwVnZ2cOHvyTgQP74+bmjr29Papsw5U1az5FaOhkVq9egdFo\nZNKkCQD4+1dm2rSJNMoK9tWrSzRp8jyDBgVgNBrp0uXN+waGO1SuXIU33+zBvHlz+OijWRw7doSg\noPdITU2hefOWaLUOjBw5mpkzp6HRaFGrVZZeT3ZGjhxLaOgkDAYDCoWCMWMm4uzszOTJ49i0aQMG\ng4F+/QZQqZIPX321lF9//R9Go5GAgPdz1DN69Hg++2w2JpMJpVLJmDETC+XnBg0a8t9/p3j66Wd4\n4YXmfPbZbHbv3omjoyNKpTJXT6Nz5658/HEowcGBJCcn0aVLNxwcHKhbtz4DB/ZDqVSh0+ksQ2gP\nwocfjmXq1AkYjUYaN25C7dp1AHOwmT17Hh07duGTT2YSGPguJpOJDz8ch62tLcHBwxg+fDB2dnY4\nOjoybtwUABITE3F01KHVah/YlsKiKO7lUEXF/ND/mYwGo2VYadSiPwGYE9SU9Wc2sP/GIcY/OwJv\nx5JLVJ964TxXP56BUuuA3+RpqFxKRpra01NHVFTigxVKSUE77xO0C+ejyMggrVMXEpetsnotpIfy\nhZVw+fIlzp2TadPmZeLj4+jTpwcbNmzL88Fekr7YuDGMVq3a4urqytKli1Cr1fTrN6BE2i4Mnp46\nLl++ydixHzJ//pelbU6R88MP3+Pg4MDLLxesjerpqXuoP/LHo+eQtTvaowSHlQxJSUQsXgRGI16B\nA0ssMDwM6l93oQsZifLKJQyVfEiaMYf09lYluPtEUq5ceb788nPCwr7BaDQyaNCQfN/4SxI3NzdG\njBiMRqPF0dGR8eOnlLZJudBqHWjfvgN79uzmpZdal7Y5RYZen8bJk/8wceK0Ym3n8QgOqTG42Dlj\nq1SXSHsmk4mbXy0n83aMWXq71lMl0u7DoJTP4NLzDUxKJSmDh5I8cjQU0wSWoGjRaDTMmvVpaZtx\nX1q2bFOqeyAKS3Eu9Swt7OzsmTw5tNjbsfrgkGHIIE4fTzWXyiXWZuzOn0n+5zjaWrVxe61TibVb\naAwGFIkJmFxcMUg1SZo4jfRWbTBkjXMKBAJBQVi9fEZM2m1MmEpsMjo1/BzRG79H6exMhfcCUdiU\nLReqjh/FpX0rdIPes0hgpA4ZJgKDQCB4IKyu53BH8iA2UY+rzu7uSqUS2ONgSEwkYsmXYDLhFTgI\nlbNzsbdZWBQJ8TjM/Aj7lctQmEykdesJej3Y25e2aQKBwAqxuuCQPTA0rlmOqJQbQPEvYzUZjUSs\nWEZm7G3cX++KVqpZcKGSwGTCbusmHCaMQRl5k8xq1Uma/RkZzZqXtmUCgcCKsbrgAOCqs2NOkFlU\n7DvZvAGnuDfAxf68g5RTJ9DWroPbq2VnkksRE4PjsGAUmRkkjx5PSvAwsCsbmfAEuTl69DCTJo3F\n378yCoWC5ORkvL0rMnlyqGVn8cMwefJY3nmnD1WqPPriiB07trF8+WK8vStajvXs+RbNmrV45Lqz\nc/z4URwddVSrllP2Jj09nY8//ojx46daNqiVBkajkblzZxEefg61Ws2YMROpVMknxzXffbeObdu2\nWLSWQkLG4evrT//+b1l2b3t7V2TcuMls3ryBSpV8LftPyjrFFhwkSbIBFgH1AT3wnizL4dnO9wKG\nAZnASSBIlmXjg7ZzZ1ipOJexppyVid60EZWrK17vvV/68wzp6SgvhGOoUg2ThweJi5aRKdXEmCVn\nICgcP4Rv59itkwVf+AA0KFeXrtXyf3koiwqo99K2bXsGDRpSrG38+ONWWrdulys4hIWtp2XLtqUa\nGAD++GMP6enpLFnyFadOnWTBgs9yrR6T5TNMmDCVmjVrWY7p9XpMJhMLFuSU5n7ttdcZMSKYBg0a\nolQqS+QeHoXi7Dm8DtjLsvy8JEnPAXOBzgCSJGmAUKCuLMspkiR9A7wGbM2vwuS0TGLSMyxKrGCW\nznCy1RVb3ujMhATzPINCgVdgEEqdruBCxYj6z30wdiTOKanc/v0v0GhIf6VDqdokeHiyK6AaDAbm\nzJnBrVuRxMRE88ILzQkMDGL69Cmo1Wpu3owgJiaaceOmIEk12bgxjO3bN+Pu7kFsbCxg1j6aMWMq\nN25cx2Aw0LPnW7Ru3Y7g4ECqVavBxYvn0Wg01KvXgEOHDpCUlMSnny7AycmpQFsTExP56KOJJCcn\nYzAYGDBgEA0bNqZPn+74+PihVqsYNWo8s2ZNIz4+HoBhw0ZRtWo1ZsyYyrVrV9Hr9XTr1hN//yr8\n9dcBzp49g79/FYsOkclk4pdfdvDVV+sB7quIeuFCOF9++QVqtZpOnbpQvnwFli5dhFKpxNu7IiEh\n40lKSmLixDG5VFjvkJKSQkjIsBz317Bh4xwb+U6cOE6TJuZNt3Xq1OXMmdO5fCLLp1m79itiYmJo\n2rQZffr0Izz8HGlpaQwfPhiDwUBg4GDq1KmLSqWienWJAwf2FXkvrDgozuDQDPgZQJblg5IkNcp2\nTg80lWX5jhqVCkgrqML0TAMAzZ+phKenjkxDJjH6WCT3Knh6Fv1D22Qw8N+CzzDEx+H3Th8qNX2m\nyNsoNFFRMGoUrF4NCgXKoCA8XTVQysGqLPCwv/v3PXsBvYrWmAJwcdFy7NgRRowIIiYmBhsbG7p3\n784rr7Tm2rVrPPdcY7p164Zer6d58+aMHz8ae3s1/v7+zJkzi7CwMHbu3EbNmpXZtCmMbdu2oVAo\n6NrVLK++e/ePeHmV44sv5pGUlETXrl1p164ltrYqmjRpyPTpUwkICMDDw5l169YwevRoLl48TZs2\nd3stOp09v/66k3PnzA9DV1dXPv/8c1auXMRLLzXnnXfeITIykl69erF7927S0/UMH/4BTz31FHPm\nzKFFixfp3bs3ly5dYuzYsSxbtoyTJ48TFhYGwP79+3nxxWdp0aI5r776KnXr3u05XLx4ERcXZ7y8\nzJpBt29H8tVXK9BoNEyaNInTp49Rvnx5jMZMvv/+B0wmE+3bt2f9+vW4u7szb948/vhjF7Vr16Zr\n1860a9eOyMhI+vTpQ2Bgv2y/CR3fffdNvr8rgyEdb29Py/dLrVbh6qrJIWHSqVNHevfujaOjI8HB\nwZw6dRhvb28CAwfQrVs3Ll26xIABA/j5559RqVQ0aFCXM2dO0qVL2RmazoviDA5OQHy2zwZJklSy\nLGdmDR9FAkiSNARwBHYVVKHJBO5O9nR8zpeoqERupUSZteJVLsUiGxCzbQtxx//BoV59bF9oWToy\nDUYj9t+sxWHaRGxiY8moUw/1imVEVa5lDqdpj6d0RGGxNvmMuLgUGjRomEMBVadzJyoqkcxMJYcO\nHWHv3n04ODig16cTFZVIWloG3t7+REUlotE4k5CQzIkTZ/Dx8Sc+Xg9AjRrmYY1Tp87QqNGzFp/4\n+Phx4oRMenomXl7mOuzsNHh4eBMVlYharSEqKi6HDxMT02jVql2OYaWoqEROn5Zp1qwVUVGJ2Nho\nsbfXcvbsZQwGIzqdJ1FRiZw69R/79v3Jli3bsu43ltRUE4MHDyckZCwpKcm0a/eK5b7i41NztH3x\n4nV0urt/z7a2DgwbNtKiiFq1ak3s7HR4e/sQFZVIbOxtIiNvERQUDJiHdBo3bkKLFi1YsmQ527bt\nQKu968s7FKbnoFTaEhERYymXmWkgNjbVct5kMtGhwxsYDGri4/U0bPgchw8fp3fvejRt2pLo6CQc\nHT1wdNRx5sxFypevgK2tIzdvRpXod/ZhX56KMzgkANmtspFl2aKTmzUnMRuoAbwhy/IDizwVp+Be\nyun/iNm6GZWbGxX6Dyi9eYbMTDSLPof0DJI+mklqwPt4ermCFT0QBffnXgXU3377H46OOkJCxnPt\n2lW2bt1kUQC9V4G0UiVfLl68gF6fhkql5uxZGQB/f39OnDhGixYtSUlJ5vz583h7e9+3jgfFz68y\n//xznBo1ahIVdYvExAScnJxz1O3n50+7dk/Rrl17YmNvs23bZqKjo5Hl08yc+Ql6vZ433ujAyy+/\nikKhwGTKOc2YXUk1KSkpT0VUGxuFxYflypVj1qxPcXR0ZN++vWg0WlauXJmnCiuYcyrcOydwL3Xr\n1mf//j9o3botp06dpEqVnLk/kpOT6du3B2vXfo9Go+Ho0b/p0KETP/64lfPnw/nwwzFER0eRnJxs\nyTORmJiAq6t1SPoXZ3DYD3QEwrLmHO6d+VuCeXjp9YeZiIa7mkpFvcchMz6OiGWLwcYGr/eDUJa0\n3ERyMup/jpHRtBnY2pKweCUmd3eM2VaPCB4Psiug9u8fyNSpE/j335Oo1WoqVfLJUwHU1dWVt99+\nh4ED++Pi4opGowGgUyezsuigQQHo9Xr69x9QZA+jvn37MXPmNPbs2Y1eryckZHyOIRbzNf2ZNesj\ntm79gZSUZPr3D8Td3Z3bt2MYOLA/NjY29Oz5NiqViqeeqsPixQvw8qqIv79Z4aBSJR9iY2+TmZmZ\npyLqnVwTYJbbHjr0Q0sGNa3WgYkTp+LiomXKlKm5VFgfRJuqefOW/P33Xwwc2B+TycS4cZMB2Lnz\nZ1JTU+jcuSuBgUF88MFA1Go1jRo9y/PPNyMjI4Pp06cwaFAACoWCsWMnWfz033+nLNnpyjrFpsqa\nbbVSPUAB9AOewTyEdDjr5w/gjgHzZVnelFd980P/Z4qOS+WqztayjPX7s1vYc20/IY2G4Ofkk1fR\nB8JkNHLt0zmknjmNZ/deuLZ7uUjqLSy2u37GccyH2ERHcfuPQxizEpFkx9qGUooT4Yu7PC6+WLPm\nK3x9/WnRouVD11EWfZGZmcnw4YOZN29Ria5WKnOqrFm9gYH3HD6T7f+PPE5zd1ip6HoOMVs3k3rm\nNA4NnsGlbbsiq7cgbG5cx3H8aOx+3IpJpSI16AOMHp4l1r5AUFbo3r0XM2d+xIsvtij15axFydat\nm+jTp59VLGMFK90Ed4eo1Ggc1Fq06qJJeJH87ylu/7gNlYcHFd4NeOQx2kJhMqFZugjtrOnYJCeR\n0eR5EufMw5Bt3bRA8CRhZ2fPlCnTS9uMIqdr126lbcIDYbXBwWA0EJMai4+uaMbhM2Jjubl8CdjY\n4P1+EEoHh4ILFQUKBeqDB8BWTeL0haT1fAseo7clgUBgnVhtcIjVx2MwGYpkSMlkMHBz6ZcYEhPx\n7P029pWrFIGFeaOIj8N2x3b0vd4GIHHWXFAqMXmUfJpTgUAguB9WGxyiUqOBoplviN78A6nnzuLY\nqDEuLYsxY5TJhN3mjThMHIvyViRxPr5kNGuOqXz54mtTIBAIHgKrDQ7RFqnuR3vbTjrxD7E//Yja\nsxzl+/YrtnkGmwvn0Y0ege3e3zDZ25M8bhIZz1rHkjaBQPDkYbXBwbLH4RF6Dhm3Y7i5YikKlQqv\nQYNRaotmYvteNF/Mw2H2dBR6Pemt2pA4ay5G/5LLXCcoO2RXZQXz8sZu3XrRunXbB6pn/vy59Ojx\nlkWTKDsHD/5JZORNOnfu+lA2/vzzj2zfvoX09HQuXbpIjRoSAJMnh+LpWe6h6ryXNWu+onHjJtSs\nWbopdvft+51Vq5ajVCrp0KETnTp1yXE+ISGeXr26UrmyWdSyefOWdO/ei507f+Lbb9diY2Mu16XL\nm9y+HcOqVcsZMWJ0adxKkWO9weERd0ebMjOJWPIlxuRkyr3dF/v77CcoKhT6NIwuriRN/5j0jq9D\nSayCEhRI1Pffknj47yKtU9eoMZ7deuZ7TXZV1pSUFIKDA/H19aV6danQ7QwdOjLPc88917TQ9dyP\n9u070L59ByIibjB58rgCdxI/KJGRNwkPP0efPv0KvrgYyczM5IsvPmXZsq/RaDQMGhRAs2bNcXO7\n+8Ipy2do0+Zlhg8PyVF24cJ5rFkThkaj5e23u9G6dTvc3NzRah04duwIDRo0LOnbKXKsJjjEx6aa\nt9JlEZUajUZlj8NDLmON3rSBtPPh6J5tgvMjbLa5H4qoKLRLF5EcMg7UalKGDCc1cBAmp7KTOU5Q\nNtBqtXTu3JXffttN9eoSixcv4J9/jmE0GunR4y1atWrDv/+e4vPP52I0GvH0LMfkyR8xcuQHjBo1\njvj4OBYsmIdKpcLJyZFJk6azZ8+vXL58iUGDhvDNN2vZvXsnSqWS+vUbEBT0AStWLCEi4gaxsbFE\nRkYwZMgIi/poQbzxxmv4+fnj71+ZHj3eYvbsGej1adjZ2RMSMo7y5SuwYcO37Nr1CwqFgtat29Ht\nnmC5efNGWmbN7d26Fcknn8wiPV1PTEw0AwYE0bz5S4VSet248Tv27v2N1NRUXFxcmDHjkxw5MZYu\nXcSJE8dztP3ZZwst11y6dJGKFX0sirT16tXn+PFjtGp1V4RQlk8jy2cIDg7ExcWVYcNG4eHhQdWq\n1UlKSkKpVGIymSzD0W3btmfFiiUiOJQ0yWrzEk+jyUh0agxeDuUfao4g6fgxYn/5GXX5CpTv+27R\nzTMYjdiv+xqHjyZhExeHoXIV0nr3ATs7TCIBT5nDs1vPAt/ySwI3NzfOnj3DgQP7iYi4zpdfrkCv\n1/P++/1o3LgJc+bMYMqU6fj7V2b79s1cunTJUvaPP/bSqlUbunfvzcmTf5OQcHdX8Pnz4fz66y4W\nL16JUqlk/PgQ9u//AwC12pa5cz/n778P8s036wodHG7dimTlyrU4O7swadJY3nyzB88//wKHDx9i\n8eIF9O3bn927d7Fo0XLArIfUpMlz+Pr6W+o4duwIr77aEYDLly/Rs+dbPPNMI06e/IcVK5bQvPlL\npKam8u67AdSoUZNFiz6nYcNn6dLlTa5evcKMGVNZuHAZ8fHxzJu3CBsbG0aMCOb06X+pV+9pSzuB\ngUH53ktycjKO2aRxtFoHkpOTclzj5+ePJNWiceMm7Nz5E/PmzSY0dDaVK1clIKAPGo2G5s1bostS\nR/b3r5wrIFkrVhMcnF01XDCYJbvj9QlkGDMfakgpIzqKmyuXoVCr8R44GBt7TZHYp/z3FLpRw1Af\nPoTRUUfizDmk9ehdJHULHm9u3ryJp2c5LlwIt7ylgnnY4+bNG9y+HWOZo3jttddzlO3Tpx9ff72S\noUMHUamSNwEBgy3nLl++RO3adS26PvXrP83Fi+cBLPMI5cpVID1dX2hbnZ1dcHY2Zz27cCGcNWu+\nYt261QAolSouXDhPZORNhg4dBJhzQFy9ejVHcIiLi8PNzaz35O7uwerVK/jxxy2AgsxMizanpcyF\nC+EcPXqY3bt3ZtWZgI2NDWq1milTxqPRaLh161aOslBwz8HBwYGUlGTLuZSUnMECzEqtdnbm/DHN\nm7dk+fLFhIef48CBfXz//VY0Gg3Tpk3k11//R6tWbVAqlahUKoxGo9Xv7raa4JCdh83+ZplnSEmh\n/Dv9sPMpGj0mzcLPcQidjMJgIK1TF5JDZ2Gs4FUkdQseb5KTk9i2bROhoR9z5cplGjRoxOjR4zEa\njaxatZyKFSvh4eHB1atX8PHxZe3aVfj43J0f27lzB6+++hrBwcP44Yf1bN36AxWyvnt+fv58++1a\nMjMzUSqVHD9+jPbtOxAefvahp72yP/B8ff3p1ett6tatz+XLlzh27Ai+vn74+1dh7tzPUSgUfPfd\nOqpWzZnpzdXVlcTEJBwcHFm+fDEdO77O88+/wI8/buWnn7ZbrstP6TU8/By//76HZctWk5aWRkDA\n27lsLajn4O9fmWvXrpKQEI9Go+X48WP06tUnxzWzZoXSokUrWrduy+HDh5CkWjg6OmJnZ4ednR1K\npRJXVzcSExMAs4y3Uqm0+sAAVhocYtLMWa/cNa4PVC5qw3ekXbyA7vmmODVrXmT2GKpWw1jRh6SP\nPyG9dcnpMQmskyNHDhMcHIhSqcRgMBAQ8D6+vv74+Phx7NgRgoLeIzU1hebNW6LVOjBq1DhmzpyG\njY0N7u7udO/em++/NyeqqVWrDrNmhaLRaLCzUzNs2GiOHz8KQNWq1WjVqg2DBgVgMpmoV68+zZu/\nRHj42SK5j8GDhzJ37izS09PR69MYOvRDqlevQaNGjQkKCiA9PYNatWrj6ZlTI6xBg4b8998pBGy3\n8AAAEXZJREFUKlSoQMuWrVm4cD5r167C07MccXFxudq5n9JrpUo+WZPI/QFzDyQvBdu8UKlUBAcP\nZ8SIIRiNRjp06ISnZzkSEuKZNSuUGTPmMHBgMDNnTmPTJrMs9+jRE/Hw8KBz564EBQWgUqmpWLGS\nZZjs/Plw6tSp+5AeLVsUmyprUTM/9H+mY1nDSq1fTWXbhV8Iqh9AbffCrfBIPHKYiC8XYOvlje+E\nydg8whyAzbWrOEyfStLUGZjKZS3t0+uhhOYVyqLiZGkhfHEXa/HFzZsRLFgwj9DQj4utjdLyxaJF\n83nhhRbUr/90wReXEA+rymqVfZ94vbkL52JXcN5bgPRbt4hctQKFrS1egwY/fGDIyECz6Avcmj2L\n/cYwNGtX3T0nJpwFgkJRoYIX1apV58yZ/0rblCIlJiaa5OTkMhUYHgWrHFa6ExycCxEcjBnpRCxe\niDE1lQr9B2D3kAlzVIcPoftwGKr/TmF0cyNx1ifoxYSzQPBQvPvue6VtQpHj7u7BqFHjStuMIsMq\ng0OcPgGVQomDquA9DlFh36K/chmnZi/i1PSFh2rPfsVSHMeNQmEykfpWX5InTsXkVrTZ5wQCgaAs\nYZXBIT49AWc7pwL3JyQe+ov4337FtmIlyvXKvZqhsGS81JLMek+T9NEsMp8r3HpwgUAgsGasbs7B\nhImE9ESc7fLfbZweeZPIr79CYWeH98CgB5pnUIafw/nNzqj+/gsAQ9XqxO3cIwKDQCB4YrC64IBS\nj9FkzHe+wZieNc+Qlkb5vu9imy0heb6kpaH9eDquLz2P7e+/Ybd1891zQg9JIBA8QVjdsJJJlQaA\ni23ewSHq2/Xor17FucVLOBVSFkC99zccQ4ajungBQwUvkqbPJv21TkVis0BwL+vWrSYsbD1hYVux\nu6dXu3nzBmJiYggIeP++ZXfs2Mby5Yvx9q5o2Yk7YcJUPD11j2xXQkI8Bw8eoF279rnOWYuS6vz5\nc7l8+Tzp6Zncvh2Do6OOpUtX3bfc46akWpRYXXAwqlOBvFcqJRz8k/jf92Dn44tnz8KtJrLb8B1O\nQQMw2diQ8n4QKaPHY3J89D80Qdnmz1/Pc+HMrSKts0rNcjRtVbXA63bu/InWrduxe/dOywaqB6Ft\n2/YMGjQEgC1bfmD9+q+ZOTP0geu5l/Dwc+zfvzdXcLAmJdWhQ0fi6akjIiKWQYMCGD16Qr7lHicl\n1aLEaoJDTHwqsSYTji7mnsP9gkN6xA0i16zGxt4er4GDsVHb5l2h0Wj+18YGffsO6F/tSMrIEDLr\n1i8O8wUCC0ePHsbbuxKvv/4G06ZN4tVXO/LPP8eZP/8TdDonlEoltWvXAWDx4gWcOfMfCQnxVKtW\ng3HjJueqLzExAVdXs1bR338fZOnSL7Gzs8PJyZmxYyeh0+n44ovPLDpDbdu2p3v3Xuzd+ytr165G\npVLh4eHJ1Kkz+PrrlYSHn2PLlh9y5IOwJiXVO2zY8C3PPvscVatWIzz8XJ7lHicl1aLEaoKDwWjC\n1ckO5wp6IgAvh5ypNY16PTcWL8Kk11NhYBC2+aTeVJ48gS5kGGm9+pDWtx84OpKwal0x34GgrNG0\nVdVCveUXNdu3b6Fjx9fx9fVHrVbz77+nmDt3JqGhs/H19eOTT8y5HpKTk9DpdMybtwij0UifPt2J\nijL3dHbt+pl//z1Jamoq169f5YsvlmIymZg9ewaLFi3H07McYWHfsHr1Cho0aEhExA2WLl2FwWBg\n0KAAGjZszK5dv9C7dx9atmzDTz9tJzk5mb59+7Nly8ZciYKsSUkVID09nS1bfmDZsq8LLPc4KakW\nJVYTHJQ2CuYENWXWoUOoUlR4O+TMgHVr/VrSr1/DuWVrdI2evW8diqREtB/PQLPsSxRGI5l1RC9B\nULIkJCRw4MB+YmNvs2HDdyQnJ/HDD99x+/ZtfLMSTtWtW59r165iZ2dPbGwskyePQ6vVkpqaalEe\nzT6sdOTI30yYEMKGDd+j1TpYsrU9/XQDlixZhJubG/XrP41CoUClUlG7dl0uXbrAkCHDWbNmFRs3\nhuHn50/z5i/labc1KakCHDhwgKeffsZyLr9yj5OSalFiNcEBIMOQwfXkm/jqKqG0UVqOx+/fR8L+\nP7Dz88ez+330+U0mbHdsx3F8CMob1zH4Vybx40/JyOomCwQlxc6dO3jttc4MHjwUgLS0NLp164RG\no+HSpYv4+1fm9On/0Ol0HDy4n1u3Ipk2bSaxsbH8/vtv3E8LrVy58mRkZODq6kpKSjLR0dF4eHhw\n/PhRfHx88fOrzI4dW+nR4y0yMzM5deoEr7zyGlu3biIgIBBXVzdmz57O77/vwcvLG6MxdxvWpKQK\n8Oeff+bIiJdfucdJSbUosargcC0pAqPJiJ9TJcsx/fVr3Fr3NTYajTk/Q7bxyzuo/9iLc7+3MKnV\nJI8IIWXoSNAUTR4HgeBB2LZtCxMnTrN8tre3p0WLVri7uxMaOhkHBwe0Wi06nY5atWqzatUKBg8e\ngEKhwNu7okV59M6wklKpIiUlmVGjxqJQKAgJGc/48aOwsVGg0zkxbtwUXFxcOHbsCO+/34+MjAxa\ntWqDJNUkKuoWISHD0God0Gg0NG3ajPT0dC5cCCcsbD3du99d0GFNSqoAFy9epEWLtgWWg8dLSbUo\nsRpV1kmjtpnq9lbz/dkt9K3VgyZeDTGmpXEldCrpNyPwChqC7plsE0oZGZCeDg4OYDLh8NFk0nq9\njaF6jdK7iSLCWtQ3SwLhi7sUpy9KQkm1KHkQX5RFJdWi5IlQZb2ScA0AX6dKmEwmIteuJv1mBC5t\n2uUIDKq/DuLa5kUcp04wH1AoSJ407bEIDAJBaSCUVJ88rGpY6XLiNeyUtpTXepLwx+8kHjyAfeUq\neL7ZHQBF7G0cPpqMZq05bWHGs8+DySR2NwsERYBQUn2ysKrgEJl8i2oulcm4dp1b36zFRuuA18Ag\nFEoldt+tx3HKeGxiYsisVZvEOfPIfLZJaZssEAgEVonVBAeTwogJE/525bmxeAGmjAy8Bg5G7e6B\nMvwcuqFBYG9P0uRQUgMHwX0mpgUCgUBQOKwnOCj1YDJR/X+nyYiMxK1la5w8PTEChmrVSZy3kIwX\nXsTo41vapgoEAoHVYzUT0vFuEdQP16M+eZZySiU15s3BacC7FhkMfc+3RGAQCASCIqLYeg6SJNkA\ni4D6gB54T5bl8GznOwKTgExgpSzLy/Krb/jLzxM9ZjdV/j2Jx5VLmJRK9K92NC9ZFfmbBQKBoEgp\nzp7D64C9LMvPA2OAuXdOSJKkBj4D2gEtgEBJkvIWQwJUQR/yzK6f8LhyiYyGjYnd9TvJU6eLwCAQ\nCATFQHEGh2bAzwCyLB8EGmU7VwsIl2U5VpbldGAf0Dy/yrz+/guFrS2Jc+YR9+MuDGJHo0AgEBQb\nxTkh7QTEZ/tskCRJJcty5n3OJQL55v1U6/UKAF3Wz5NOUSR2eVwQvriL8MVdhC8ejeLsOSSQ8zlu\nkxUY7ndOB+QWaBEIBAJBqVCcwWE/8CqAJEnPASeznTsNVJckyU2SJFvMQ0oHitEWgUAgEDwAxSa8\nl221Uj1AAfQDngEcZVlemm21kg3m1UoLi8UQgUAgEDwwVqPKKhAIBIKSw2o2wQkEAoGg5BDBQSAQ\nCAS5EMFBIBAIBLkoc8J7RS27Yc0Uwhe9gGGYfXESCJJl2VgathYnBfkh23VLgduyLI8pYRNLjEJ8\nJxoDn2JeBHITeFuW5bTSsLW4KYQv3gJGAgbMz4ovS8XQEkSSpCbAx7Isv3TP8Qd+bpbFnkORym5Y\nOfn5QgOEAi1lWX4B8ybC10rFyuInTz/cQZKk94EnYdt8ft8JBbAM6CfL8h2FAr9SsbJkKOh78QnQ\nBngBGClJkmsJ21eiSJIUAiwH7O85/lDPzbIYHIpUdsPKyc8XeqCpLMspWZ9VwGP5hkj+fkCSpKZA\nE2BJyZtW4uTnixpADDBckqS9gJssy3LJm1hi5Pu9AE5gfmmyx9yTetyXZp4Hut7n+EM9N8ticLiv\n7EYe5wqU3bBy8vSFLMtGWZYjASRJGgI4ArtK3sQSIU8/SJLkBUwGgkvDsFIgv78PD6ApsADzG3Nr\nSZJalbB9JUl+vgA4BRwB/gW2y7L8WKswyLK8Eci4z6mHem6WxeAgZDfukp8vkCTJRpKkT4C2wBuy\nLD+ub0b5+aEb5ofiDsxDC70lSXq3ZM0rUfLzRQzmN8TTsixnYH6rvvdt+nEiT19IklQP6ABUBvyB\ncpIkdStxC8sGD/XcLIvBQchu3CU/X4B5GMUeeD3b8NLjSJ5+kGX5c1mWG2ZNwM0C1suyvKo0jCwh\n8vtOXAAcJUmqlvX5RcxvzY8r+fkiHkgFUmVZNgC3gMd6ziEfHuq5WeZ2SAvZjbvk5wvgcNbPH9wd\nS50vy/KmUjC1WCnoO5HtuneBmk/IaqW8/j5aYQ6SCuBPWZaHlpqxxUwhfDEQ6A+kYx6PH5A15v7Y\nIkmSP/CtLMvPSZLUm0d4bpa54CAQCASC0qcsDisJBAKBoJQRwUEgEAgEuRDBQSAQCAS5EMFBIBAI\nBLkQwUEgEAgEuShzwnuCJ5OsJXhngf/uOdVRluWreZSZAiDL8pRHaPddzEJ1V7IOaYC9mEUMM/Mq\nl0dd04DDsixvlSTpN1mWW2YdPy7L8tMPa2NWHXuASkBS1iEnzPsa3rqzUz6PcoFAoizL3zxK+4In\nDxEcBGWJG4/6EH1Itsqy/C6AJElKYA8wGJj/IJXIsjwp28eXsh0vqnt6T5blPWBZ478BGAGMzqdM\nU8z3IxA8ECI4CMo8kiTVAb7AvPmvHDBXluXPs51XAyuBOlmHFsmyvCxLeXIJ4AMYgbGyLP8vv7Zk\nWTZIkvQnZhE7JEnqh1n22YRZpycYs+jh/dpbhflB/ExW2b9kWW4iSZIJUGPunTSQZTlSkiQ3zNo/\nfkBrYFrWNRcxb9aKKcAtDphlQ/7Kaqtblp2arJ/3AFugE9BKkqQI4PiD+kPw5CLmHARlCW9Jko5n\n+xmVdfw9IFSW5cZAS2D6PeWaYlYgbcBdiWYwv/mvlGW5IeaH5BJJknTkgyRJ7sArwH5JkuoC44EW\nsizXBZIxi/zl1R4Asix/kPVvk2zHMoHvMWtBAbwBbAZcMO9ofjmrvl+Aj/Mwb7kkSf9kPegPYhZa\n/CyrFzEQeE2W5fpZ9Y3KevBvBSbJsvzLw/hD8OQieg6CskRew0ojgfaSJI3FLJXgeM/5U4AkSdIv\nmAX47gyztAFqZs0FgPnNvCrmN+jsdJIk6ThmCQYb4AfgG8xDS9uyvcUvBb7C/PC9X3sFsQaYh1k1\ntRcwAbPUuC/wmyRJAErgdh7l35NleU+WRPlGYMcdOQhJkroAHSVzJS9hTnBzL4X1h0AggoPAKggD\nYoFtwLdAz+wnZVmOkSSpNmZ12leBo1mflUArWZZvA0iS5A3cb/LWMueQnaw38uwoAFU+7eWLLMuH\ns8TPGgOVZFn+U5KkzsA+WZY7ZbVpT04FzfvV86ckSZ8DX0uSVB+z+OLfmIPP75jzGNxPwryw/hAI\nxLCSwCpoi3loZAvmTFZ3Jo7J+n8nYC3wI/AB5hU9PsCvQFDWNU9hfmhqH6DdPZh7FW5ZnwdgfsPP\nq73s3Jtb4A7rMI/7f5v1+S/geUmSamR9ngjMKYRtn2KedxiIeX7ECMzAfM+vYA4EYE4LeceOR/WH\n4AlCBAeBNTAF2CdJ0lHgZeASZp3+O/yEWZ75X+AQ8IMsyyeBIcBzkiSdAL4D+siynFjYRmVZPgHM\nBPZKknQG8/zAhHzay84W4J+snkB21gJPZ/2LLMs3MSuHhkmSdBLzZPbIQtimxzwfMhmz4uhx4Axw\nFHOwupMe9H/AOEmS3uQR/SF4shCqrAKBQCDIheg5CAQCgSAXIjgIBAKBIBciOAgEAoEgFyI4CAQC\ngSAXIjgIBAKBIBciOAgEAoEgFyI4CAQCgSAX/wcfr87c/umdxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18cf48c6fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, classifier.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n",
    "\n",
    "rf_roc_auc = roc_auc_score(y_test, rf.predict(X_test))\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "dtree_roc_auc = roc_auc_score(y_test, dtree.predict(X_test))\n",
    "dt_fpr, dt_tpr, dt_thresholds = roc_curve(y_test, dtree.predict_proba(X_test)[:,1])\n",
    "\n",
    "ada_roc_auc = roc_auc_score(y_test, ada.predict(X_test))\n",
    "ada_fpr, ada_tpr, ada_thresholds = roc_curve(y_test, ada.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)\n",
    "plt.plot(dt_fpr, dt_tpr, label='Decision Tree (area = %0.2f)' % dtree_roc_auc)\n",
    "plt.plot(ada_fpr, ada_tpr, label='AdaBoost (area = %0.2f)' % ada_roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the above ROC Graph , we see AdaBoost Model has highest AUC value of 0.70 and it is closest to the top left corner which is one of the creteria for a good model. Next good model as per ROC curve is the Logistic Regression model.*\n",
    "\n",
    "*Next I will use **SMOTE(Synthetic Minority Over-sampling Technique)** algorithm to combat Imbalanced Classes in my Machine Learning Dataset and test the model based on the modified data sample.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalanced Dataset Counter({0: 924, 1: 924})\n"
     ]
    }
   ],
   "source": [
    "# Count the number of occurrence of the list items\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "x_sm, y_sm = sm.fit_sample(X_train,y_train)\n",
    "print('Rebalanced Dataset {}'.format(Counter(y_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.82      0.82       924\n",
      "          1       0.82      0.83      0.83       924\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1848\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.80      0.86       309\n",
      "          1       0.42      0.76      0.54        59\n",
      "\n",
      "avg / total       0.86      0.79      0.81       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on Balance Dataset\n",
    "classifier_sm = LogisticRegression()\n",
    "classifier_sm.fit(x_sm, y_sm)\n",
    "print(\"[Train Classification Report:]\")\n",
    "print(classification_report(y_sm, classifier_sm.predict(x_sm)))\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, classifier_sm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.81      0.82       924\n",
      "          1       0.82      0.84      0.83       924\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1848\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87       309\n",
      "          1       0.43      0.75      0.55        59\n",
      "\n",
      "avg / total       0.86      0.80      0.82       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on Balance Dataset using 'L1' regularization\n",
    "classifier_sm_1 = LogisticRegression(penalty = 'l1')\n",
    "classifier_sm_1.fit(x_sm, y_sm)\n",
    "print(\"[Train Classification Report:]\")\n",
    "print(classification_report(y_sm, classifier_sm_1.predict(x_sm)))\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, classifier_sm_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** AdaBoost Model Performance on Balance Dataset using SMOTE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Accuracy score: 0.850543478261\n",
      "\n",
      "\n",
      "[Training] Accuracy score: 0.882032667877\n",
      "\n",
      "\n",
      "[Training Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93       924\n",
      "          1       0.94      0.91      0.93       924\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1848\n",
      "\n",
      "[Test Classification Report:]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91       309\n",
      "          1       0.53      0.54      0.54        59\n",
      "\n",
      "avg / total       0.85      0.85      0.85       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_sm_ada = AdaBoostClassifier()\n",
    "classifier_sm_ada.fit(x_sm, y_sm)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "y_predict_test_sm = classifier_sm_ada.predict(X_test)\n",
    "print(\"[Test] Accuracy score:\" ,accuracy_score(y_predict_test_sm, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the accuracy from the training data.\n",
    "y_predict_train_sm = classifier_sm_ada.predict(X_train)\n",
    "print(\"[Training] Accuracy score:\" ,accuracy_score(y_predict_train_sm, y_train))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"[Training Classification Report:]\")\n",
    "print(classification_report(y_sm, classifier_sm_ada.predict(x_sm)))\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(y_test, classifier_sm_ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above Classification Report, we find that training performance metrics are--as expected--slightly better than their test set counterpart in terms of accuracy score.\n",
    "And this time, we noticed that the recall for both Class 01 and 1 are similar to Precision values of respective class.\n",
    "So how well Classifier predict about employee leaving and when a employee leaves, how well classifier predict it, both the conditions are handled better by this new model.\n",
    "\n",
    "But the Prediction and Recall for Minority Class (Class 1) is still not very good compared to Class 0 precision and Recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
